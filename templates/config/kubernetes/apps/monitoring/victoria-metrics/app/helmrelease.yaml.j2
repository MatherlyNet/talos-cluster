#% if monitoring_enabled | default(false) and monitoring_stack | default('victoriametrics') == 'victoriametrics' %#
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: victoria-metrics-k8s-stack
spec:
  chartRef:
    kind: OCIRepository
    name: victoria-metrics-k8s-stack
  interval: 1h
  values:
    # VictoriaMetrics Single (lightweight, recommended for homelab)
    vmsingle:
      enabled: true
      spec:
        retentionPeriod: "#{ metrics_retention | default('7d') }#"
        storage:
          storageClassName: "#{ storage_class | default('local-path') }#"
          resources:
            requests:
              storage: "#{ metrics_storage_size | default('50Gi') }#"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            memory: 1Gi
        #| Health probes - vmsingle listens on port 8428, NOT 8429 #|
        readinessProbe:
          httpGet:
            path: /health
            port: 8428
          initialDelaySeconds: 5
          periodSeconds: 15
        livenessProbe:
          httpGet:
            path: /health
            port: 8428
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5

    # VMAgent for scraping
    vmagent:
      enabled: true
      spec:
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            memory: 256Mi
        # Health probes for reliability
        readinessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 5
          periodSeconds: 15
        livenessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 30
          periodSeconds: 30

    # Grafana
    grafana:
      enabled: true
      #| Plugins for enhanced observability #|
      #| Ref: https://grafana.com/grafana/plugins/victoriametrics-metrics-datasource/ #|
      plugins:
        - victoriametrics-metrics-datasource
      #| Grafana.ini configuration for Grafana 12+ features #|
      #| Ref: https://grafana.com/blog/2025/05/07/grafana-12-release-all-the-new-features/ #|
      grafana.ini:
        feature_toggles:
          #| Enable Grafana 12 Drilldown apps (formerly Explore Metrics/Logs/Traces) #|
          enable: exploreMetrics,exploreLogs,traceToLogs,correlations,nestedFolders
        unified_alerting:
          #| Grafana-managed alerting (replaces legacy alerting removed in Grafana 11) #|
          enabled: true
        alerting:
          #| Disable legacy alerting (deprecated) #|
          enabled: false
        users:
          #| Allow viewing dashboards without login (read-only) #|
          viewers_can_edit: false
        auth.anonymous:
          #| Anonymous access disabled by default - enable if you want public dashboards #|
          enabled: false
        analytics:
          #| Disable analytics reporting #|
          reporting_enabled: false
          check_for_updates: false
        log:
          mode: console
          level: warn
      #| Admin credentials from SOPS-encrypted secret #|
      #| Configure grafana_admin_user and grafana_admin_password in cluster.yaml #|
      admin:
        existingSecret: grafana-admin-secret
        userKey: admin-user
        passwordKey: admin-password
      #| Ingress disabled - using Gateway API HTTPRoute for envoy-internal instead #|
      #| See httproute.yaml for the HTTPRoute that exposes Grafana internally #|
      ingress:
        enabled: false
      persistence:
        enabled: true
        storageClassName: "#{ storage_class | default('local-path') }#"
        size: 5Gi
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          memory: 512Mi
      # Health probes for reliability
      readinessProbe:
        httpGet:
          path: /api/health
          port: 3000
        initialDelaySeconds: 10
        periodSeconds: 10
      livenessProbe:
        httpGet:
          path: /api/health
          port: 3000
        initialDelaySeconds: 30
        periodSeconds: 30
        timeoutSeconds: 5
      # Sidecar disabled - using grafana.dashboards for provisioning instead
      # The victoria-metrics chart doesn't allow both sidecar and dashboards simultaneously
      sidecar:
        dashboards:
          enabled: false
      # Dashboard provisioning
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: infrastructure
              folder: Infrastructure
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/infrastructure
            - name: network
              folder: Network
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/network
            - name: gitops
              folder: GitOps
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/gitops
      #| Dashboard datasource mapping uses array format for ${DS_PROMETHEUS} variable replacement #|
      #| Ref: https://github.com/grafana/helm-charts/blob/main/charts/grafana/README.md #|
      dashboards:
        infrastructure:
          # Kubernetes Core (dotdc collection - uses both DS_PROMETHEUS and datasource)
          kubernetes-global:
            gnetId: 15757
            revision: 43
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
              - name: datasource
                value: VictoriaMetrics
          kubernetes-nodes:
            gnetId: 15759
            revision: 32
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
              - name: datasource
                value: VictoriaMetrics
          kubernetes-pods:
            gnetId: 15760
            revision: 36
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
              - name: datasource
                value: VictoriaMetrics
          # Node metrics (uses both DS_PROMETHEUS and datasource variables)
          node-exporter-full:
            gnetId: 1860
            revision: 37
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
              - name: datasource
                value: VictoriaMetrics
          # Control plane (uses datasource variable only)
          kubernetes-etcd:
            gnetId: 20330
            revision: 1
            datasource:
              - name: datasource
                value: VictoriaMetrics
          # CoreDNS (uses both DS_PROMETHEUS and datasource)
          kubernetes-coredns:
            gnetId: 15762
            revision: 18
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
              - name: datasource
                value: VictoriaMetrics
          # cert-manager (uses Datasource variable, not DS_PROMETHEUS)
          cert-manager:
            gnetId: 11001
            revision: 1
            datasource:
              - name: Datasource
                value: VictoriaMetrics
        network:
          # Cilium Agent (BPF operations, API latency, forwarding stats)
          cilium-agent:
            gnetId: 16611
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Operator (IPAM, node management)
          cilium-operator:
            gnetId: 16612
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Hubble (flows, drops, DNS, HTTP, TCP)
          cilium-hubble:
            gnetId: 16613
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Network Policy Verdicts (policy enforcement tracking)
          cilium-policy-verdicts:
            gnetId: 18015
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Network Monitoring (endpoints, BPF maps, connectivity)
          cilium-network-monitoring:
            gnetId: 24056
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Envoy Gateway (uses datasource variable, not DS_PROMETHEUS)
          envoy-gateway:
            gnetId: 24460
            revision: 1
            datasource:
              - name: datasource
                value: VictoriaMetrics
          # Envoy Proxy (uses DS_PROMETHEUS-04 variable)
          envoy-proxy:
            gnetId: 21329
            revision: 1
            datasource:
              - name: DS_PROMETHEUS-04
                value: VictoriaMetrics
        gitops:
          flux2:
            gnetId: 16714
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
    #| Moved to defaultDatasources.extra per chart changelog (see below) #|

    #| Additional datasources for unified observability #|
    #| Note: grafana.additionalDataSources was renamed to defaultDatasources.extra #|
    #| Ref: https://docs.victoriametrics.com/helm/victoriametrics-k8s-stack/changelog/ #|
    defaultDatasources:
      extra:
        #| Prometheus alias for dashboard compatibility (many dashboards use ${DS_PROMETHEUS}) #|
        #| The uid: prometheus is CRITICAL - it allows Grafana to resolve ${DS_PROMETHEUS} variable #|
        - name: Prometheus
          uid: prometheus
          type: prometheus
          url: http://vmsingle-victoria-metrics-k8s-stack.monitoring.svc:8428
          access: proxy
          isDefault: false
#% if loki_enabled | default(false) %#
        - name: Loki
          uid: loki
          type: loki
          url: http://loki:3100
          access: proxy
          isDefault: false
          jsonData:
            maxLines: 1000
#% endif %#
#% if tracing_enabled | default(false) %#
        - name: Tempo
          uid: tempo
          type: tempo
          url: http://tempo:3200
          access: proxy
          isDefault: false
          jsonData:
            tracesToLogs:
              datasourceUid: loki
              tags: ['namespace', 'pod']
              mappedTags: [{ key: 'service.name', value: 'service' }]
              mapTagNamesEnabled: true
              filterByTraceID: true
              filterBySpanID: true
            tracesToMetrics:
              #| Use 'prometheus' UID - our Prometheus alias datasource that points to VictoriaMetrics #|
              datasourceUid: prometheus
              tags: [{ key: 'service.name', value: 'service' }]
              queries:
                - name: 'Request Rate'
                  query: 'sum(rate(traces_spanmetrics_calls_total{$$__tags}[5m]))'
            serviceMap:
              datasourceUid: prometheus
            nodeGraph:
              enabled: true
            search:
              hide: false
            lokiSearch:
              datasourceUid: loki
#% endif %#

    # AlertManager
    alertmanager:
      enabled: true
      spec:
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            memory: 128Mi
        # Health probes for reliability
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 10
          periodSeconds: 30
      config:
        global:
          resolve_timeout: 5m
        route:
          group_by: ['alertname', 'namespace', 'severity']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 12h
          receiver: 'null'
          routes:
            - match:
                alertname: Watchdog
              receiver: 'null'
            - match:
                severity: critical
              receiver: 'null'
        receivers:
          - name: 'null'

    # Node Exporter
    prometheus-node-exporter:
      enabled: true
      resources:
        requests:
          cpu: 20m
          memory: 32Mi
        limits:
          memory: 64Mi

    # kube-state-metrics
    kube-state-metrics:
      enabled: true
      resources:
        requests:
          cpu: 20m
          memory: 64Mi
        limits:
          memory: 128Mi

    # kubelet scraping
    kubelet:
      enabled: true
      spec:
        # For Talos Linux
        metricRelabelConfigs:
          - action: labeldrop
            regex: (uid)
          - action: labeldrop
            regex: (id|name)
          - action: drop
            source_labels: ["__name__"]
            regex: (rest_client_request_duration_seconds_bucket|rest_client_request_duration_seconds_sum|rest_client_request_duration_seconds_count)

    # etcd monitoring - Talos exposes metrics on HTTP port 2381
    # Ref: https://docs.siderolabs.com/kubernetes-guides/monitoring-and-observability/etcd-metrics
    kubeEtcd:
      enabled: true
      endpoints:
#% for node in nodes %#
#% if node.controller %#
        - #{ node.address }#
#% endif %#
#% endfor %#
      service:
        enabled: true
        port: 2381
        targetPort: 2381
      vmScrape:
        spec:
          endpoints:
            - port: http-metrics
              scheme: http

    # API Server
    kubeApiServer:
      enabled: true

    # Controller Manager - Talos Linux binds to 0.0.0.0 but certs only valid for localhost
    # Ref: https://github.com/VictoriaMetrics/VictoriaMetrics/issues/6476
    kubeControllerManager:
      enabled: true
      vmScrape:
        spec:
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              port: http-metrics
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                serverName: localhost
                insecureSkipVerify: true

    # Scheduler - Talos Linux binds to 0.0.0.0 but certs only valid for 127.0.0.1
    # Ref: https://github.com/VictoriaMetrics/VictoriaMetrics/issues/6476
    kubeScheduler:
      enabled: true
      vmScrape:
        spec:
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              port: http-metrics
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                serverName: "127.0.0.1"
                insecureSkipVerify: true
#% endif %#