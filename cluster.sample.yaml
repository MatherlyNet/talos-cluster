# yaml-language-server: $schema=./.taskfiles/template/resources/cluster.schema.json
---
# =============================================================================
# TALOS CLUSTER - Required
# =============================================================================
# -- The network CIDR for the nodes.
# (REQUIRED) / (e.g. 192.168.1.0/24)
node_cidr: ""

# -- DNS servers to use for the cluster.
#    (OPTIONAL) / (DEFAULT: ["1.1.1.1", "1.0.0.1"]) / (Cloudflare DNS)
# node_dns_servers: []

# -- NTP servers to use for the cluster.
#    (OPTIONAL) / (DEFAULT: ["162.159.200.1", "162.159.200.123"]) / (Cloudflare NTP)
# node_ntp_servers: []

# -- The default gateway for the nodes.
#    (OPTIONAL) / (DEFAULT: the first IP in the node_cidr)
# node_default_gateway: ""

# -- Attach a vlan tag to the Talos nodes. Not needed if ports on your switch are tagged or you are not using VLANs.
#    (OPTIONAL) / (REF: https://www.talos.dev/latest/advanced/advanced-networking/#vlans)
# node_vlan_tag: ""

# -- When true, Proxmox handles VLAN tagging (access port mode) and Talos sees untagged traffic.
#    When false (default), Talos creates VLAN sub-interfaces (trunk port / bare-metal mode).
#    Set to true when using OpenTofu/Proxmox VM provisioning with node_vlan_tag.
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_vlan_mode: false

# -- The IP address of the Kube API.
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cluster_api_addr: ""

# -- Additional SANs to add to the Kube API cert. This is useful if you want to call the Kube API by hostname rather than IP
#    (OPTIONAL) / (e.g. ["mycluster.example.com"])
# cluster_api_tls_sans: []

# -- The pod CIDR for the cluster, this must NOT overlap with any existing networks and should be a /16 (64K IPs).
#    (REQUIRED) / (DEFAULT: "10.42.0.0/16")
cluster_pod_cidr: ""

# -- The service CIDR for the cluster, this must NOT overlap with any existing networks and should be a /16 (64K IPs).
#    (REQUIRED) / (DEFAULT: "10.43.0.0/16")
cluster_svc_cidr: ""

# -- The Load balancer IP for k8s_gateway (split DNS for internal resolution)
#    (CONDITIONAL) / Required ONLY when NOT using UniFi DNS integration
#    When unifi_host and unifi_api_key are set, k8s-gateway is replaced by
#    external-dns-unifi and this setting is ignored.
#    (NOTE: Choose an unused IP in node_cidr if using k8s_gateway)
# cluster_dns_gateway_addr: ""

# -- The Load balancer IP for the internal gateway
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cluster_gateway_addr: ""

# -- GitHub repository
#    (REQUIRED) / (e.g. "onedr0p/cluster-template")
repository_name: ""

# -- GitHub repository branch
#    (OPTIONAL) / (DEFAULT: "main")
# repository_branch: ""

# -- Repository visibility (public or private)
#    (OPTIONAL) / (DEFAULT: "public") / (NOTE: See the README for information when set private)
# repository_visibility: ""

# -- Domain you wish to use from your Cloudflare account
#    (REQUIRED) / (e.g. "example.com")
cloudflare_domain: ""

# -- API Token for Cloudflare with the 'Zone:DNS:Edit' and 'Account:Cloudflare Tunnel:Read' permissions
#    (REQUIRED) (NOTE: See the README for information on creating this)
cloudflare_token: ""

# -- The Load balancer IP for the external gateway
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cloudflare_gateway_addr: ""
# =============================================================================
# CILIUM BGP CONFIGURATION - Optional for multi-VLAN environments
# =============================================================================
# Enable BGP peering between Cilium and your router for dynamic routing.
# This allows LoadBalancer IPs to be advertised via BGP instead of L2/ARP.
#
# When to use BGP:
# - Multi-VLAN environment requiring cross-subnet service access
# - Faster failover needed (~9s with tuned timers vs ARP cache timeout)
# - Source IP preservation with externalTrafficPolicy: Local
#
# Requirements:
# - UniFi gateway with UniFi OS 4.1.13+ (or UXG-Enterprise 4.1.8+)
# - FRR config uploaded to gateway (generated in unifi/bgp.conf after configure)
#
# REF: https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-v2/
# REF: docs/guides/bgp-unifi-cilium-implementation.md

# -- The IP address of the BGP router (your gateway on the node network)
#    (OPTIONAL) / (e.g. "192.168.1.1" or VLAN gateway like "192.168.23.254")
#    NOTE: Use the gateway IP on the same VLAN as your nodes, not the management IP
# cilium_bgp_router_addr: ""

# -- The BGP ASN for your router (use private range 64512-65534)
#    (OPTIONAL) / (e.g. "64513")
# cilium_bgp_router_asn: ""

# -- The BGP ASN for Kubernetes nodes (must differ from router ASN for eBGP)
#    (OPTIONAL) / (e.g. "64514")
# cilium_bgp_node_asn: ""

# -- Dedicated CIDR for LoadBalancer IPs (separate from node_cidr)
#    (OPTIONAL) / (e.g. "172.20.10.0/24")
#    NOTE: If set, update UniFi prefix-list to match this CIDR
# cilium_lb_pool_cidr: ""

# -- The load balancer mode for cilium.
#    (OPTIONAL) / (DEFAULT: "dsr") / (NOTE: accepted values are 'dsr' or 'snat') / (REF: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/)
# cilium_loadbalancer_mode: ""

# -- BGP Hold Time in seconds (failure detection = 3x keepalive or hold timeout)
#    (OPTIONAL) / (DEFAULT: 30) / (Minimum: 3)
#    NOTE: Lower values = faster failure detection, but more BGP traffic
# cilium_bgp_hold_time: 30

# -- BGP Keepalive Time in seconds (sent every N seconds to peer)
#    (OPTIONAL) / (DEFAULT: 10) / (Minimum: 1)
# cilium_bgp_keepalive_time: 10

# -- Enable BGP Graceful Restart for smoother failover during Cilium restarts
#    (OPTIONAL) / (DEFAULT: false)
#    NOTE: Requires UniFi FRR config to also enable graceful-restart
# cilium_bgp_graceful_restart: false

# -- Graceful Restart timeout in seconds
#    (OPTIONAL) / (DEFAULT: 120)
# cilium_bgp_graceful_restart_time: 120

# -- Maximum ECMP paths for load balancing across advertising nodes
#    (OPTIONAL) / (DEFAULT: 3)
#    NOTE: When multiple nodes advertise the same LoadBalancer IP, traffic is
#    distributed across up to this many paths for better load distribution
# cilium_bgp_ecmp_max_paths: 3

# -- MD5 password for BGP session authentication (RFC 2385)
#    (OPTIONAL) / Must match password configured in UniFi FRR config
#    NOTE: When set, a Kubernetes Secret will be created and referenced by
#    CiliumBGPPeerConfig for TCP MD5 authentication
# cilium_bgp_password: ""

# =============================================================================
# CILIUM NETWORK POLICIES - Zero-Trust Network Security
# =============================================================================
# CiliumNetworkPolicies enforce zero-trust networking with L3-L7 controls.
# Policies are applied per-namespace with explicit ingress/egress allowlists.
# REF: https://docs.cilium.io/en/stable/security/policy/
# REF: docs/research/cilium-network-policies-jan-2026.md

# -- Enable CiliumNetworkPolicies for zero-trust networking
#    Creates namespace-scoped policies with default-deny and explicit allowlists
#    (OPTIONAL) / (DEFAULT: false)
# network_policies_enabled: false

# -- Network policy enforcement mode: "audit" or "enforce"
#    audit: Policies created with enableDefaultDeny: false (observe only via Hubble)
#    enforce: Policies created with enableDefaultDeny: true (active blocking)
#    Start with audit mode to observe traffic patterns before enforcing
#    (OPTIONAL) / (DEFAULT: "audit")
# network_policies_mode: "audit"

# =============================================================================
# UNIFI DNS INTEGRATION - Optional for internal DNS via external-dns webhook
# =============================================================================
# When configured, replaces k8s_gateway with native UniFi DNS record management.
# Requires UniFi Network v9.0.0+ for API key authentication (current stable: 9.5.21)

# -- The UniFi controller host URL
#    (OPTIONAL) / (e.g. "https://192.168.1.1")
# unifi_host: ""

# -- The UniFi API key for DNS management
#    (OPTIONAL) / (Created in UniFi Admin → Control Plane → Integrations)
# unifi_api_key: ""

# -- The UniFi site identifier
#    (OPTIONAL) / (DEFAULT: "default")
# unifi_site: ""

# -- Whether using non-UDM hardware (Cloud Key, self-hosted controller)
#    (OPTIONAL) / (DEFAULT: false)
# unifi_external_controller: false

# =============================================================================
# TALOS UPGRADE CONTROLLER (tuppr) - Automated OS/K8s upgrades
# =============================================================================
# tuppr manages Talos OS and Kubernetes upgrades through GitOps-driven CRs.
# Update these versions to trigger automated rolling upgrades.

# -- Talos OS version for automated upgrades
#    (OPTIONAL) / (DEFAULT: "1.12.0")
# talos_version: "1.12.0"

# -- Kubernetes version for automated upgrades
#    (OPTIONAL) / (DEFAULT: "1.35.0")
# kubernetes_version: "1.35.0"

# =============================================================================
# PROXMOX CSI CONFIGURATION - Optional for persistent storage
# =============================================================================
# Proxmox CSI provisions PersistentVolumes directly on Proxmox storage.
# Requires Proxmox API token with storage permissions.

# -- Enable Proxmox CSI for persistent storage
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_csi_enabled: false

# -- Proxmox API endpoint (shared with other Proxmox integrations)
#    (OPTIONAL) / (e.g. "https://pve.example.com:8006")
# proxmox_endpoint: ""

# -- Proxmox CSI API token ID (format: user@realm!token-name)
#    (OPTIONAL) / (e.g. "kubernetes-csi@pve!csi")
# proxmox_csi_token_id: ""

# -- Proxmox CSI API token secret
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# proxmox_csi_token_secret: ""

# -- Proxmox storage pool for PVs
#    (OPTIONAL) / (e.g. "local-zfs")
# proxmox_csi_storage: ""

# -- Proxmox region identifier (cluster name)
#    (OPTIONAL) / (DEFAULT: "pve")
# proxmox_region: "pve"

# =============================================================================
# PROXMOX CCM CONFIGURATION - Optional for node labeling/lifecycle
# =============================================================================
# Proxmox CCM provides node labeling, lifecycle management, and topology awareness.
# Use Proxmox CCM instead of Talos CCM when running on Proxmox infrastructure.
# NOTE: Talos CCM and Proxmox CCM are mutually exclusive - only one can be enabled.

# -- Enable Proxmox CCM (disables Talos CCM)
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_ccm_enabled: false

# -- Proxmox CCM API token ID (format: user@realm!token-name)
#    (OPTIONAL) / (e.g. "kubernetes-ccm@pve!ccm")
#    NOTE: Use separate token from CSI for least-privilege principle
# proxmox_ccm_token_id: ""

# -- Proxmox CCM API token secret
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# proxmox_ccm_token_secret: ""

# =============================================================================
# INFRASTRUCTURE (OpenTofu/Proxmox) - Optional for VM deployments
# =============================================================================

# -- Proxmox API endpoint
#    (OPTIONAL) / (e.g. "https://pve.example.com:8006/api2/json")
#    Required only for automated VM provisioning via OpenTofu
# proxmox_api_url: ""

# -- Proxmox node name to create VMs on
#    (OPTIONAL) / (e.g. "pve")
# proxmox_node: ""

# -- Proxmox storage for ISO images
#    (OPTIONAL) / (DEFAULT: "local")
# proxmox_iso_storage: ""

# -- Proxmox storage for VM disks
#    (OPTIONAL) / (DEFAULT: "local-lvm")
# proxmox_disk_storage: ""

# -- Proxmox API token for OpenTofu VM provisioning
#    Create at: Datacenter → Permissions → API Tokens → Add
#    Format: user@realm!token-name (e.g., root@pam!terraform)
#    NOTE: Separate from CSI/CCM tokens for least-privilege
#    (OPTIONAL) / Required when infrastructure_enabled
# proxmox_api_token_id: ""
# proxmox_api_token_secret: ""

# =============================================================================
# INFRASTRUCTURE CREDENTIALS (OpenTofu R2 State Backend)
# =============================================================================
# Credentials for the tfstate-worker HTTP backend on Cloudflare R2.
# These are used by `task infra:*` commands for state management.

# -- Cloudflare Account ID
#    Dashboard → Overview → Account ID (right sidebar)
#    (OPTIONAL) / Required for R2 state backend
# cf_account_id: ""

# -- tfstate-worker Basic Auth credentials
#    Must match secrets configured in your tfstate-worker deployment
#    (OPTIONAL) / (DEFAULT: "terraform")
# tfstate_username: "terraform"
# tfstate_password: ""

# =============================================================================
# OBSERVABILITY - Monitoring Stack (kube-prometheus-stack)
# =============================================================================
# Full-stack observability with metrics, logs, and distributed tracing.
# Uses kube-prometheus-stack: Prometheus + Grafana + AlertManager + node-exporter

# -- Enable monitoring stack (Prometheus + Grafana + AlertManager)
#    (OPTIONAL) / (DEFAULT: false)
# monitoring_enabled: false

# -- Monitoring stack choice
#    Currently only "prometheus" (kube-prometheus-stack) is supported
#    (OPTIONAL) / (DEFAULT: "prometheus")
# monitoring_stack: "prometheus"

# -- Enable Hubble network observability (requires monitoring_enabled)
#    Provides network flow visibility via Cilium
#    (OPTIONAL) / (DEFAULT: false)
# hubble_enabled: false

# -- Enable Hubble UI web interface
#    (OPTIONAL) / (DEFAULT: false)
# hubble_ui_enabled: false

# -- Grafana subdomain (creates grafana.<cloudflare_domain>)
#    (OPTIONAL) / (DEFAULT: "grafana")
# grafana_subdomain: "grafana"

# -- Grafana admin username
#    (OPTIONAL) / (DEFAULT: "admin")
# grafana_admin_user: "admin"

# -- Grafana admin password (SOPS-encrypted)
#    (OPTIONAL) / Set BEFORE initial deployment - password changes after first
#    login require CLI reset: kubectl -n monitoring exec deploy/kube-prometheus-stack-grafana
#    -- grafana-cli admin reset-admin-password <new-password>
# grafana_admin_password: ""

# -- Metrics retention period
#    (OPTIONAL) / (DEFAULT: "7d")
# metrics_retention: "7d"

# -- Metrics storage size
#    (OPTIONAL) / (DEFAULT: "50Gi")
# metrics_storage_size: "50Gi"

# -- Storage class for monitoring (uses proxmox-zfs if available)
#    (OPTIONAL) / (DEFAULT: "local-path")
# storage_class: "local-path"

# -- Enable infrastructure alerting rules (PrometheusRule)
#    Generates alerts for: Node health, Control Plane, etcd, Cilium, CoreDNS,
#    Envoy Gateway, Certificates, Flux GitOps, Workloads, Storage
#    (OPTIONAL) / (DEFAULT: true)
# monitoring_alerts_enabled: true

# -- Memory utilization % threshold for NodeMemoryHighUtilization alert
#    (OPTIONAL) / (DEFAULT: 90) / (Range: 50-99)
# node_memory_threshold: 90

# -- CPU utilization % threshold for NodeCPUHighUtilization alert
#    (OPTIONAL) / (DEFAULT: 90) / (Range: 50-99)
# node_cpu_threshold: 90

# -- Enable log aggregation with Loki
#    (OPTIONAL) / (DEFAULT: false)
# loki_enabled: false

# -- Log retention period
#    (OPTIONAL) / (DEFAULT: "7d")
# logs_retention: "7d"

# -- Log storage size
#    (OPTIONAL) / (DEFAULT: "50Gi")
# logs_storage_size: "50Gi"

# =============================================================================
# OBSERVABILITY - Distributed Tracing (Optional)
# =============================================================================
# Tempo for distributed tracing with Alloy as the unified collector.

# -- Enable distributed tracing with Tempo
#    Requires monitoring_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# tracing_enabled: false

# -- Tracing sample rate (percentage, 1-100)
#    100 = trace all requests; 10 = trace 10% of requests
#    (OPTIONAL) / (DEFAULT: 10)
# tracing_sample_rate: 10

# -- Trace retention period
#    (OPTIONAL) / (DEFAULT: "72h")
# trace_retention: "72h"

# -- Trace storage size
#    (OPTIONAL) / (DEFAULT: "10Gi")
# trace_storage_size: "10Gi"

# -- Cluster name for trace metadata
#    (OPTIONAL) / (DEFAULT: "matherlynet")
# cluster_name: "matherlynet"

# -- Observability namespace for Tempo, Alloy, and other monitoring components
#    (OPTIONAL) / (DEFAULT: "monitoring")
# observability_namespace: "monitoring"

# -- Environment tag for traces and logs (production, staging, development)
#    (OPTIONAL) / (DEFAULT: "production")
# environment: "production"

# =============================================================================
# OBSERVABILITY - Grafana Dashboard Monitoring (Component-Specific)
# =============================================================================
# Component-specific toggles for Grafana dashboards and ServiceMonitors.
# Each requires monitoring_enabled: true as a prerequisite.
# REF: docs/guides/grafana-dashboards-implementation.md

# -- Enable Keycloak Grafana monitoring (ServiceMonitor + Dashboards)
#    Deploys Keycloak Troubleshooting and Capacity Planning dashboards
#    Also deploys ServiceMonitor for metrics collection on management port 9000
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true, keycloak_enabled: true)
# keycloak_monitoring_enabled: false

# -- Enable RustFS Grafana monitoring (ServiceMonitor + Dashboard)
#    Deploys MinIO-compatible storage dashboard for RustFS metrics
#    Also deploys ServiceMonitor for /minio/v2/metrics/cluster endpoint
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true, rustfs_enabled: true)
# rustfs_monitoring_enabled: false

# -- Enable Loki Grafana monitoring (Stack Monitoring Dashboard)
#    Deploys Loki Stack Monitoring dashboard (grafana.com ID: 14055)
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true, loki_enabled: true)
# loki_monitoring_enabled: false

# =============================================================================
# GRAFANA OIDC AUTHENTICATION - Native OAuth for Grafana RBAC
# =============================================================================
# Enable Grafana's native OAuth to provide RBAC and role-based access control.
# This creates a dedicated Keycloak client for Grafana with proper role mappings.
# When combined with gateway-level OIDC, provides near-seamless SSO via auto_login.
#
# FLOW: User -> Envoy Gateway (OIDC) -> Grafana -> auto_login -> Keycloak -> Grafana
# Users with existing Keycloak sessions experience ~200-500ms redirect (no login page).
#
# ROLE MAPPING: Keycloak roles are mapped to Grafana roles via JMESPath:
#   - grafana-admin -> GrafanaAdmin (server administrator)
#   - grafana-editor -> Editor (can create/modify dashboards)
#   - default -> Viewer (read-only access)
#
# SETUP WORKFLOW:
#   1. Enable grafana_oidc_enabled below
#   2. Generate client secret: openssl rand -hex 32
#   3. Set grafana_oidc_client_secret (SOPS-encrypted after task configure)
#   4. Add Grafana roles to keycloak_realm_roles (see Keycloak section)
#   5. Run 'task configure' and 'task reconcile'
#   6. IMPORTANT: Keycloak realm changes require full cleanup/redeploy
#      See: docs/research/grafana-sso-authentication-integration-jan-2026.md
#
# REF: docs/research/grafana-sso-authentication-integration-jan-2026.md

# -- Enable Grafana native OAuth with Keycloak
#    Creates dedicated Keycloak client for Grafana RBAC
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true, keycloak_enabled: true)
# grafana_oidc_enabled: false

# -- Grafana OIDC client secret (SOPS-encrypted)
#    GENERATE: openssl rand -hex 32
#    IMPORTANT: Must use hex encoding (not base64) for URL safety
#    This secret is shared between Keycloak client and Grafana configuration
#    (REQUIRED when grafana_oidc_enabled: true)
# grafana_oidc_client_secret: ""

# =============================================================================
# RUSTFS SHARED OBJECT STORAGE - S3-compatible storage for cluster services
# =============================================================================
# RustFS is a high-performance, Rust-based S3-compatible object storage system.
# When enabled, Loki automatically switches to SimpleScalable mode with S3.
# Performance: 2.3x faster than MinIO for small objects, Apache 2.0 license.
# REF: https://github.com/rustfs/rustfs
#
# IMPORTANT: RustFS does NOT support 'mc admin' commands for user/policy management.
# Access keys for services (Loki, etc.) must be created manually via the Console UI.
# REF: https://docs.rustfs.com/administration/iam/access-token.html
#
# SETUP WORKFLOW:
#   1. Enable rustfs_enabled and set rustfs_secret_key below
#   2. Run 'task configure' and 'task reconcile' to deploy RustFS
#   3. Wait for rustfs-bucket-setup job to complete (creates buckets)
#   4. Access RustFS Console at https://rustfs.<your-domain>
#   5. Login with rustfs_access_key / rustfs_secret_key (root credentials)
#   6. Create custom 'loki-storage' policy (Identity -> Policies -> Create Policy)
#      See: docs/research/rustfs-shared-storage-loki-simplescalable-jan-2026.md
#      Section: "Phase 2.5: Loki IAM Configuration" for policy JSON
#   7. Create 'monitoring' group with 'loki-storage' policy attached
#   8. Create 'loki' user in 'monitoring' group
#   9. Generate Access Key for 'loki' user (Service Accounts tab)
#   10. Copy access key and secret key (secret shown only once!)
#   11. Update loki_s3_access_key / loki_s3_secret_key below with generated values
#   12. Run 'task configure' and 'task reconcile' to apply Loki credentials
#
# NOTE: Tempo uses local filesystem storage by default, not RustFS/S3.
# NOTE: Custom 'loki-storage' policy scopes access to only loki-* buckets (least privilege).

# -- Enable RustFS shared storage
#    When enabled, Loki uses SimpleScalable mode with S3 backend
#    (OPTIONAL) / (DEFAULT: false)
# rustfs_enabled: false

# -- RustFS subdomain (creates rustfs.<cloudflare_domain>)
#    (OPTIONAL) / (DEFAULT: "rustfs")
# rustfs_subdomain: "rustfs"

# -- Number of RustFS nodes
#    Single node (1) for simple deployments, 4+ for distributed mode
#    Note: Helm chart creates data PVCs only for 1, 4, or 16 replicas
#    (OPTIONAL) / (DEFAULT: 1)
# rustfs_replicas: 1

# -- Data storage size per RustFS node
#    Used for volumeClaimTemplates via storageclass.dataStorageSize
#    (OPTIONAL) / (DEFAULT: "20Gi")
# rustfs_data_volume_size: "20Gi"

# -- Log storage size per RustFS node
#    Used for volumeClaimTemplates via storageclass.logStorageSize
#    (OPTIONAL) / (DEFAULT: "1Gi")
# rustfs_log_volume_size: "1Gi"

# -- StorageClass for RustFS PVCs
#    Falls back to global storage_class if not set
#    (OPTIONAL) / (DEFAULT: uses storage_class or "local-path")
# rustfs_storage_class: "proxmox-zfs"

# -- RustFS root admin username
#    (OPTIONAL) / (DEFAULT: "rustfsadmin")
# rustfs_access_key: "rustfsadmin"

# -- RustFS root admin password (SOPS-encrypted)
#    Generate with: openssl rand -base64 32
#    (REQUIRED when rustfs_enabled)
# rustfs_secret_key: ""

# -- Workload optimization profile
#    Options: GeneralPurpose, AiTraining, DataAnalytics, WebWorkload, IndustrialIoT, SecureStorage
#    (OPTIONAL) / (DEFAULT: "DataAnalytics")
# rustfs_buffer_profile: "DataAnalytics"

# -- Loki S3 access key (created manually via RustFS Console UI)
#    After deploying RustFS, create an access key in Console -> Identity -> Users
#    Copy the generated access key here
#    (REQUIRED when rustfs_enabled and loki_enabled)
# loki_s3_access_key: "PLACEHOLDER_CREATE_IN_RUSTFS_CONSOLE"

# -- Loki S3 secret key (created manually via RustFS Console UI, SOPS-encrypted)
#    Copy the generated secret key from RustFS Console here
#    (REQUIRED when rustfs_enabled and loki_enabled)
# loki_s3_secret_key: ""

# =============================================================================
# EXTERNAL SECRETS OPERATOR - Sync secrets from external providers
# =============================================================================
# External Secrets Operator syncs secrets from external secret stores.
# Supported providers: 1Password, Bitwarden, HashiCorp Vault
# REF: https://external-secrets.io/
# REF: docs/guides/k8s-at-home-remaining-implementation.md

# -- Enable External Secrets Operator
#    (OPTIONAL) / (DEFAULT: false)
# external_secrets_enabled: false

# -- External secrets provider: "1password", "bitwarden", or "vault"
#    (OPTIONAL) / (DEFAULT: "1password")
# external_secrets_provider: "1password"

# -- 1Password Connect host URL (required when provider is "1password")
#    (OPTIONAL) / (e.g. "http://onepassword-connect:8080")
# onepassword_connect_host: ""

# =============================================================================
# TALOS BACKUP - Automated etcd snapshots with S3 storage
# =============================================================================
# Talos Backup creates periodic etcd snapshots and uploads them to S3-compatible
# storage with Age encryption. Required for disaster recovery.
#
# OPTION A: Internal RustFS (when rustfs_enabled: true)
#   backup_s3_endpoint: "http://rustfs-svc.storage.svc.cluster.local:9000"
#   backup_s3_bucket: "etcd-backups"
#   - Create access key via RustFS Console (see docs/guides/talos-backup-rustfs-implementation.md)
#   - Benefits: No egress costs, low latency, unified storage
#   - Limitation: Backups lost if cluster is destroyed
#
# OPTION B: External Cloudflare R2 (true disaster recovery)
#   backup_s3_endpoint: "https://<account-id>.r2.cloudflarestorage.com"
#   backup_s3_bucket: "cluster-backups"
#   - Benefits: Survives cluster destruction, free egress
#   - Setup: Create R2 bucket + API token in Cloudflare dashboard
#
# REF: docs/guides/talos-backup-rustfs-implementation.md

# -- S3-compatible endpoint for backups
#    For RustFS internal: "http://rustfs-svc.storage.svc.cluster.local:9000"
#    For Cloudflare R2: "https://<account-id>.r2.cloudflarestorage.com"
#    (OPTIONAL) / (Enables talos_backup_enabled when set with backup_s3_bucket)
# backup_s3_endpoint: ""

# -- S3 bucket name for backups
#    For RustFS: "etcd-backups" (created by RustFS bucket setup job)
#    For R2: your bucket name (e.g. "cluster-backups")
#    (OPTIONAL)
# backup_s3_bucket: ""

# -- S3 access key ID
#    For RustFS: Create via Console UI with 'backup-storage' policy
#    For R2: Cloudflare API token with R2 write access
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# backup_s3_access_key: ""

# -- S3 secret access key
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# backup_s3_secret_key: ""

# -- S3 region (required by AWS SDK, any value works for S3-compatible storage)
#    (OPTIONAL) / (DEFAULT: "us-east-1")
# backup_s3_region: "us-east-1"

# -- Age public key for backup encryption (use same as cluster Age key)
#    Get from: cat age.key | grep "public key"
#    (OPTIONAL) / (e.g. "age1...")
# backup_age_public_key: ""

# =============================================================================
# CLOUDNATIVEPG OPERATOR - Production PostgreSQL for Kubernetes
# =============================================================================
# CloudNativePG provides production-grade PostgreSQL clusters with automated
# failover, backups, and monitoring. Deployed as a shared cluster resource.
# Single operator in cnpg-system namespace serves multiple database clusters.
# REF: https://cloudnative-pg.io/documentation/
# REF: docs/guides/cnpg-implementation.md
#
# SHARED RESOURCE PATTERN:
#   cnpg-system/           # Operator namespace (deployed by this config)
#   ├── cloudnative-pg     # Operator deployment
#   identity/              # App namespace (Keycloak example)
#   └── keycloak-postgres  # CNPG Cluster CR (app-specific)
#
# DEPENDENCY CHAIN: CloudNativePG → Keycloak → JWT/OIDC SecurityPolicy

# -- Enable CloudNativePG operator deployment
#    (OPTIONAL) / (DEFAULT: false)
# cnpg_enabled: false

# -- PostgreSQL image for new clusters
#    Options: 18.1-standard-trixie (with JIT, recommended)
#             18.1-minimal-trixie (smaller footprint)
#    NOTE: With Barman Cloud Plugin enabled, standard/minimal images work for S3 backups
#    The plugin provides barman-cloud binaries via sidecar container
#    REF: https://cloudnative-pg.io/plugin-barman-cloud/docs/
#    (OPTIONAL) / (DEFAULT: "ghcr.io/cloudnative-pg/postgresql:18.1-standard-trixie")
# cnpg_postgres_image: "ghcr.io/cloudnative-pg/postgresql:18.1-standard-trixie"

# -- Default storage class for CNPG clusters
#    Falls back to global storage_class if not set
#    (OPTIONAL) / (DEFAULT: uses storage_class or "local-path")
# cnpg_storage_class: ""

# -- Operator priority class
#    (OPTIONAL) / (DEFAULT: "system-cluster-critical")
# cnpg_priority_class: "system-cluster-critical"

# -- Deploy operator on control-plane nodes only
#    (OPTIONAL) / (DEFAULT: true for homelab single control-plane)
# cnpg_control_plane_only: true

# -- Enable CNPG backups to RustFS S3
#    Requires rustfs_enabled: true
#    Create access key via RustFS Console UI (see docs)
#    (OPTIONAL) / (DEFAULT: false)
# cnpg_backup_enabled: false

# -- S3 access key for CNPG backups (created via RustFS Console)
#    (REQUIRED when cnpg_backup_enabled: true)
# cnpg_s3_access_key: ""

# -- S3 secret key for CNPG backups (SOPS-encrypted)
#    (REQUIRED when cnpg_backup_enabled: true)
# cnpg_s3_secret_key: ""

# =============================================================================
# CLOUDNATIVEPG PGVECTOR EXTENSION - Vector similarity search for AI/ML
# =============================================================================
# pgvector provides native vector data types for similarity search, embedding
# storage, and AI-driven use cases. Mounted via ImageVolume (no custom images).
# REF: https://github.com/pgvector/pgvector
# REF: https://cloudnative-pg.io/docs/1.28/imagevolume_extensions/
#
# REQUIREMENTS:
#   - PostgreSQL 18+ (extension_control_path support)
#   - Kubernetes 1.35+ (ImageVolume beta enabled by default)
#   - CloudNativePG 1.27+ (extension mounting support)

# -- Enable pgvector extension for CNPG clusters
#    (OPTIONAL) / (DEFAULT: false)
# cnpg_pgvector_enabled: false

# -- pgvector extension image
#    (OPTIONAL) / (DEFAULT: "ghcr.io/cloudnative-pg/pgvector:0.8.1-18-trixie")
# cnpg_pgvector_image: "ghcr.io/cloudnative-pg/pgvector:0.8.1-18-trixie"

# -- pgvector version (must match image tag)
#    (OPTIONAL) / (DEFAULT: "0.8.1")
# cnpg_pgvector_version: "0.8.1"

# =============================================================================
# CLOUDNATIVEPG BARMAN CLOUD PLUGIN - External backup plugin for S3
# =============================================================================
# Barman Cloud Plugin replaces the deprecated in-tree barmanObjectStore.
# Provides barman-cloud binaries via sidecar container - no -system- images needed.
# REF: https://cloudnative-pg.io/plugin-barman-cloud/docs/
#
# DEPRECATION TIMELINE:
#   - CNPG 1.26: barmanObjectStore deprecated, plugin recommended
#   - CNPG 1.29: In-tree barman-cloud support removed
#
# ARCHITECTURE:
#   cnpg-system/
#   ├── cloudnative-pg    # CNPG operator
#   └── barman-cloud      # Plugin deployment (provides barman-cloud binaries)
#
# USAGE:
#   Each backup-enabled PostgreSQL cluster gets an ObjectStore CRD that
#   configures the S3 destination. The cluster references the plugin via
#   spec.plugins instead of spec.backup.barmanObjectStore.

# -- Enable Barman Cloud Plugin for S3 backups
#    Required for any PostgreSQL cluster backups (Keycloak, LiteLLM, Langfuse, Obot)
#    (OPTIONAL) / (DEFAULT: false)
# cnpg_barman_plugin_enabled: false

# -- Barman Cloud Plugin version
#    (OPTIONAL) / (DEFAULT: "0.10.0")
# cnpg_barman_plugin_version: "0.10.0"

# -- Plugin log level for debugging
#    (OPTIONAL) / (DEFAULT: "info") / (Options: trace, debug, info, warn, error)
# cnpg_barman_plugin_log_level: "info"

# =============================================================================
# DRAGONFLY CACHE - Redis-compatible in-memory data store
# =============================================================================
# Dragonfly provides a high-performance, multi-threaded drop-in replacement
# for Redis with 25x+ better throughput and 25% less memory usage.
# Deployed as a shared cluster resource in the 'cache' namespace.
# Uses the Dragonfly Operator for Kubernetes-native lifecycle management.
# REF: https://www.dragonflydb.io/docs/getting-started/kubernetes-operator
# REF: docs/research/dragonfly-redis-alternative-integration-jan-2026.md
#
# USE CASES:
#   - Session storage for distributed applications (Keycloak, LiteLLM)
#   - Caching layer (L2 cache behind PostgreSQL)
#   - Rate limiting for API endpoints
#   - Pub/Sub messaging for lightweight event distribution
#
# ARCHITECTURE:
#   cache/                    # Namespace for caching services
#   └── dragonfly/            # Dragonfly operator + instance
#       ├── operator/         # Operator deployment in dragonfly-operator-system
#       └── app/              # Dragonfly CR + supporting resources
#
# SERVICE DISCOVERY:
#   Applications connect via: dragonfly.cache.svc.cluster.local:6379

# -- Enable Dragonfly cache deployment
#    (OPTIONAL) / (DEFAULT: false)
# dragonfly_enabled: false

# -- Dragonfly server version
#    (OPTIONAL) / (DEFAULT: "v1.36.0")
# dragonfly_version: "v1.36.0"

# -- Dragonfly Operator version
#    (OPTIONAL) / (DEFAULT: "1.3.1")
# dragonfly_operator_version: "1.3.1"

# -- Number of Dragonfly replicas (1 = standalone, 2+ = HA with replication)
#    (OPTIONAL) / (DEFAULT: 1)
# dragonfly_replicas: 1

# -- Maximum memory for Dragonfly (with unit: mb, gb)
#    (OPTIONAL) / (DEFAULT: "512mb")
# dragonfly_maxmemory: "512mb"

# -- Number of proactor threads (set based on available CPU)
#    (OPTIONAL) / (DEFAULT: 2)
# dragonfly_threads: 2

# -- Dragonfly authentication password (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    (REQUIRED when dragonfly_enabled: true)
# dragonfly_password: ""

# -- Deploy Dragonfly on control-plane nodes only
#    (OPTIONAL) / (DEFAULT: false)
# dragonfly_control_plane_only: false

# -- CPU resource request
#    (OPTIONAL) / (DEFAULT: "100m")
# dragonfly_cpu_request: "100m"

# -- Memory resource request
#    (OPTIONAL) / (DEFAULT: "256Mi")
# dragonfly_memory_request: "256Mi"

# -- Memory resource limit
#    (OPTIONAL) / (DEFAULT: "1Gi")
# dragonfly_memory_limit: "1Gi"

# -- Enable cache mode (LRU-like eviction when approaching maxmemory)
#    Recommended for session storage and caching use cases
#    (OPTIONAL) / (DEFAULT: false)
# dragonfly_cache_mode: false

# -- Slow query log threshold in microseconds
#    Queries slower than this are logged for debugging
#    (OPTIONAL) / (DEFAULT: 10000 = 10ms)
# dragonfly_slowlog_threshold: 10000

# -- Maximum number of slow queries to retain in log
#    (OPTIONAL) / (DEFAULT: 128)
# dragonfly_slowlog_max_len: 128

# -- Enable Dragonfly S3 snapshots to RustFS
#    Requires rustfs_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# dragonfly_backup_enabled: false

# -- S3 endpoint for Dragonfly backups
#    For RustFS internal: "rustfs-svc.storage.svc.cluster.local:9000"
#    (OPTIONAL when dragonfly_backup_enabled: true)
# dragonfly_s3_endpoint: "rustfs-svc.storage.svc.cluster.local:9000"

# -- S3 access key for Dragonfly backups (created via RustFS Console)
#    (REQUIRED when dragonfly_backup_enabled: true)
# dragonfly_s3_access_key: ""

# -- S3 secret key for Dragonfly backups (SOPS-encrypted)
#    (REQUIRED when dragonfly_backup_enabled: true)
# dragonfly_s3_secret_key: ""

# -- Snapshot cron schedule
#    (OPTIONAL) / (DEFAULT: "0 */6 * * *" - every 6 hours)
# dragonfly_snapshot_cron: "0 */6 * * *"

# -- Enable Dragonfly Grafana monitoring (PodMonitor + Dashboard)
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true)
# dragonfly_monitoring_enabled: false

# -- Enable ACL (Access Control Lists) for multi-tenant access
#    Creates per-service users with key pattern restrictions
#    (OPTIONAL) / (DEFAULT: false)
# dragonfly_acl_enabled: false

# -- Keycloak-specific password for ACL (SOPS-encrypted)
#    When not set, uses dragonfly_password
#    (OPTIONAL when dragonfly_acl_enabled: true)
# dragonfly_keycloak_password: ""

# -- Application cache password for ACL (SOPS-encrypted)
#    When not set, uses dragonfly_password
#    (OPTIONAL when dragonfly_acl_enabled: true)
# dragonfly_appcache_password: ""

# -- LiteLLM cache password for ACL (SOPS-encrypted)
#    When not set, uses dragonfly_password
#    (OPTIONAL when dragonfly_acl_enabled: true)
# dragonfly_litellm_password: ""

# -- Langfuse cache password for ACL (SOPS-encrypted)
#    Required when Langfuse uses shared Dragonfly with ACL enabled.
#    Langfuse keys are prefixed with langfuse:* for namespace isolation.
#    (OPTIONAL when dragonfly_acl_enabled: true and langfuse_enabled: true)
# dragonfly_langfuse_password: ""

# =============================================================================
# KEYCLOAK OIDC PROVIDER - Identity and Access Management
# =============================================================================
# Keycloak provides OIDC/OAuth2 authentication for JWT SecurityPolicy (API auth)
# and OIDC SecurityPolicy (web SSO). Deploys in the 'identity' namespace using
# the official Keycloak Operator (version-matched, CRD-based).
# REF: https://www.keycloak.org/operator/installation
# REF: docs/guides/keycloak-implementation.md
#
# DEPLOYMENT OPTIONS:
#   embedded: Uses in-cluster PostgreSQL StatefulSet (dev/testing)
#   cnpg: Uses CloudNativePG Cluster (production) - requires cnpg_enabled: true
#
# DEPENDENCY CHAIN: CloudNativePG (if cnpg mode) → Keycloak → JWT/OIDC SecurityPolicy

# -- Enable Keycloak deployment
#    (OPTIONAL) / (DEFAULT: false)
# keycloak_enabled: false

# -- Keycloak subdomain (creates auth.${cloudflare_domain})
#    (OPTIONAL) / (DEFAULT: "auth")
# keycloak_subdomain: "auth"

# -- Keycloak realm name (for application tokens)
#    (OPTIONAL) / (DEFAULT: "matherlynet")
# keycloak_realm: "matherlynet"

# -- Keycloak admin password (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    Note: Admin username is always "admin" (operator default)
#    (REQUIRED when keycloak_enabled: true)
# keycloak_admin_password: ""

# -- Keycloak database mode: "embedded" or "cnpg"
#    embedded: Uses in-cluster PostgreSQL StatefulSet (dev/testing)
#    cnpg: Uses CloudNativePG Cluster (production, requires cnpg_enabled: true)
#    (OPTIONAL) / (DEFAULT: "embedded")
# keycloak_db_mode: "embedded"

# -- PostgreSQL credentials (SOPS-encrypted)
#    Used by both embedded PostgreSQL and CloudNativePG modes
#    (REQUIRED when keycloak_enabled: true)
# keycloak_db_user: "keycloak"
# keycloak_db_password: ""
# keycloak_db_name: "keycloak"

# -- Keycloak storage size (for PostgreSQL PVC)
#    (OPTIONAL) / (DEFAULT: "5Gi" for embedded, "10Gi" for cnpg)
# keycloak_storage_size: "5Gi"

# -- Keycloak replicas (1 for dev, 2+ for HA)
#    When >1, distributed Infinispan cache is enabled for session clustering
#    (OPTIONAL) / (DEFAULT: 1)
# keycloak_replicas: 1

# -- PostgreSQL instances (only for cnpg mode, 1 for dev, 3 for HA)
#    (OPTIONAL) / (DEFAULT: 1)
# keycloak_db_instances: 1

# -- Keycloak Operator version
#    (OPTIONAL) / (DEFAULT: "26.5.0")
# keycloak_operator_version: "26.5.0"

# -- Keycloak S3 access key for PostgreSQL backups (created via RustFS Console)
#    Create policy 'keycloak-storage' scoped to keycloak-backups bucket only
#    Create group 'identity' with keycloak-storage policy attached
#    Create user 'keycloak-backup' in identity group
#    (REQUIRED when keycloak_backup_enabled: true)
# keycloak_s3_access_key: ""

# -- Keycloak S3 secret key for PostgreSQL backups (SOPS-encrypted)
#    (REQUIRED when keycloak_backup_enabled: true)
# keycloak_s3_secret_key: ""

# -- Backup schedule for embedded mode pg_dump (cron format)
#    Only applies when keycloak_db_mode: "embedded"
#    CNPG mode uses continuous WAL archiving instead
#    (OPTIONAL) / (DEFAULT: "0 2 * * *" - daily at 2:00 AM UTC)
# keycloak_backup_schedule: "0 2 * * *"

# -- Backup retention days for embedded mode pg_dump
#    Only applies when keycloak_db_mode: "embedded"
#    CNPG mode uses retentionPolicy in barmanObjectStore
#    (OPTIONAL) / (DEFAULT: 7)
# keycloak_backup_retention_days: 7

# -- Enable Keycloak OpenTelemetry tracing
#    Requires tracing_enabled: true (Tempo deployed in monitoring namespace)
#    When enabled, Keycloak exports traces to Tempo via OTLP gRPC (port 4317)
#    (OPTIONAL) / (DEFAULT: false)
# keycloak_tracing_enabled: false

# -- Keycloak tracing sample rate (0.0 to 1.0)
#    1.0 = trace 100% of requests; 0.1 = trace 10% of requests
#    Production recommended: 0.1 (10%); Development: 1.0 (100%)
#    (OPTIONAL) / (DEFAULT: "0.1")
# keycloak_tracing_sample_rate: "0.1"

# -- keycloak-config-cli version for realm configuration management
#    Format: <cli-version>-<keycloak-version> (e.g., "6.4.0-26.1.0")
#    Used by keycloak-config-cli Job to apply realm configuration via Admin API
#    Supports incremental updates (unlike KeycloakRealmImport which is one-time only)
#    REF: https://github.com/adorsys/keycloak-config-cli
#    REF: docs/research/keycloak-configuration-as-code-gitops-jan-2026.md
#    (OPTIONAL) / (DEFAULT: "6.4.0-26.1.0")
# keycloak_config_cli_version: "6.4.0-26.1.0"

# =============================================================================
# KEYCLOAK CLIENT CONFIGURATION TRACKING
# =============================================================================
# These variables track important client configuration settings. When changed,
# they trigger automatic recreation of the keycloak-config-cli Job via Flux.
# This ensures configuration changes are applied without manual intervention.
#
# FLOW: Change variable → task configure → Git commit → Flux detects change →
#       Job annotation changes → Flux recreates Job → Config applied
# -----------------------------------------------------------------------------

# -- Headlamp PKCE method (Proof Key for Code Exchange)
#    Options: "" (disabled), "S256" (enabled with SHA256), "plain" (not recommended)
#    Headlamp v0.39.0 does not support PKCE - keep disabled (empty string)
#    As a confidential client with client_secret, PKCE is not required
#    (OPTIONAL) / (DEFAULT: "")
# headlamp_pkce_method: ""

# -- Configuration change trigger (bump to force Job recreation)
#    Increment this value when making changes to realm configuration that
#    don't affect other tracked variables (e.g., role mappings, IdP settings)
#    (OPTIONAL) / (DEFAULT: 1)
# keycloak_config_version: 1

# -- Keycloak realm roles (RBAC role hierarchy)
#    Define custom roles for your realm following Kubernetes RBAC patterns.
#    These roles are used by IdP mappers and can be included in JWT tokens.
#    Roles are automatically created during realm import.
#    Best practice: Follow principle of least privilege with hierarchical roles.
#    (OPTIONAL) / (DEFAULT: admin, operator, developer, viewer, user)
#    REF: https://kubernetes.io/docs/concepts/security/rbac-good-practices/
# keycloak_realm_roles:
#   - name: "admin"
#     description: "Full administrative access to all applications and settings"
#   - name: "operator"
#     description: "Operational access - manage services, view logs, restart pods"
#   - name: "developer"
#     description: "Development access - CI/CD, debugging tools, dev environments"
#   - name: "viewer"
#     description: "Read-only access to dashboards and status pages"
#   - name: "user"
#     description: "Basic authenticated user access to standard applications"

# =============================================================================
# OIDC/JWT CONFIGURATION - Optional for API authentication via SecurityPolicy
# =============================================================================
# JWT-based authentication for API endpoints, validating tokens against JWKS.
# When configured, creates a SecurityPolicy targeting HTTPRoutes with
# label "security: jwt-protected".
# REF: https://gateway.envoyproxy.io/latest/concepts/gateway_api_extensions/security-policy/
# REF: docs/guides/envoy-gateway-observability-security.md

# -- OIDC provider name (used in SecurityPolicy)
#    (OPTIONAL) / (DEFAULT: "keycloak")
# oidc_provider_name: "keycloak"

# -- OIDC issuer URL (JWT token issuer - must match "iss" claim in tokens)
#    (OPTIONAL) / (e.g. "https://auth.example.com/realms/myrealm")
# oidc_issuer_url: ""

# -- OIDC JWKS URI for JWT validation (public keys endpoint)
#    (OPTIONAL) / (e.g. "https://auth.example.com/realms/myrealm/protocol/openid-connect/certs")
# oidc_jwks_uri: ""

# -- Additional claims to extract from JWT and pass as headers to backend services
#    (OPTIONAL) / Headers must start with "X-"
#    Format: YAML list with 'name' (JWT claim path) and 'header' (HTTP header name)
#    Common Keycloak claims:
#      - preferred_username: User's display name
#      - email: User's email address
#      - realm_access.roles: Array of realm-level roles
#      - resource_access.<client>.roles: Client-specific roles
#      - groups: User's group memberships (if mapper configured)
#    NOTE: Nested claims use dot notation (e.g., "realm_access.roles")
#    Example (comprehensive claim extraction for IdP role mapping):
#    oidc_additional_claims:
#      - name: "preferred_username"
#        header: "X-Username"
#      - name: "email"
#        header: "X-Email"
#      - name: "realm_access.roles"
#        header: "X-User-Roles"
#      - name: "resource_access.envoy-gateway.roles"
#        header: "X-Client-Roles"
#      - name: "groups"
#        header: "X-Groups"
#    NOTE: "groups" claim requires Keycloak "Group Membership" mapper on the client
# oidc_additional_claims: []
#oidc_additional_claims:
#  - name: "preferred_username"
#    header: "X-Username"
#  - name: "email"
#    header: "X-Email"
#  - name: "realm_access.roles"
#    header: "X-User-Roles"
#  - name: "resource_access.envoy-gateway.roles"
#    header: "X-Client-Roles"
#  - name: "groups"
#    header: "X-Groups"

# =============================================================================
# OIDC WEB SSO CONFIGURATION - Session-based browser authentication
# =============================================================================
# OIDC-based web SSO for browser applications, using cookie sessions.
# Creates a SecurityPolicy targeting HTTPRoutes with label "security: oidc-protected".
# REF: https://gateway.envoyproxy.io/docs/tasks/security/oidc/
# REF: docs/guides/native-oidc-securitypolicy-implementation.md
#
# SETUP WORKFLOW:
#   1. Enable keycloak_enabled (provides OIDC issuer) OR set oidc_issuer_url manually
#   2. Generate a URL-safe client secret (MUST use hex, NOT base64):
#      openssl rand -hex 32
#      IMPORTANT: Do NOT use base64 - it contains + and = which break OAuth2 token exchange!
#   3. Set oidc_client_secret below (SOPS-encrypted after task configure)
#   4. Run 'task configure' and 'task reconcile'
#   5. Label HTTPRoutes with 'security: oidc-protected' to enable SSO
#
# AUTOMATIC CLIENT BOOTSTRAP (when keycloak_enabled: true):
#   When both keycloak_enabled and oidc_sso_enabled are true, the 'envoy-gateway'
#   OIDC client is automatically created in the Keycloak realm with:
#   - Confidential client type with the provided oidc_client_secret
#   - Wildcard redirect URIs: https://*.${cloudflare_domain}/oauth2/callback
#   - PKCE enabled for enhanced security
#   - Default scopes: openid, profile, email
#   No manual Keycloak admin console setup required!
#
# KEY DIFFERENCES FROM JWT SecurityPolicy:
#   JWT: Stateless API auth, validates Bearer tokens against JWKS (label: jwt-protected)
#   OIDC SSO: Stateful browser SSO, manages cookie sessions (label: oidc-protected)

# -- Enable OIDC Web SSO authentication
#    Requires: oidc_issuer_url, oidc_client_id, oidc_client_secret
#    Optional: oidc_redirect_url (omit for dynamic redirect - recommended)
#    (OPTIONAL) / (DEFAULT: false)
# oidc_sso_enabled: false

# -- OIDC client ID registered in your identity provider
#    (REQUIRED when oidc_sso_enabled: true) / (DEFAULT: "envoy-gateway")
#    When keycloak_enabled: true, this client is auto-created via realm import.
#    For external IdPs: Create a client with this ID in your IdP.
# oidc_client_id: "envoy-gateway"

# -- OIDC client secret (SOPS-encrypted)
#    (REQUIRED when oidc_sso_enabled: true)
#    GENERATE: openssl rand -hex 32
#    IMPORTANT: MUST use hex encoding (not base64) - base64 contains + and = characters
#    that are URL-unsafe and will cause OAuth2 token exchange to fail with "invalid_client_credentials".
#    When keycloak_enabled: true, this secret is automatically configured in Keycloak
#    via realm import - no manual Keycloak admin console setup required!
#    For external IdPs: Copy the client secret from your IdP's client configuration.
# oidc_client_secret: ""

# -- OAuth2 callback URL for OIDC redirect
#    (OPTIONAL - OMIT for dynamic redirect, which is the RECOMMENDED approach)
#    This is where your IdP redirects after authentication. Envoy Gateway intercepts
#    this callback, completes the OAuth flow, then redirects user to original destination.
#
#    IMPORTANT: Wildcards (*.domain.com) are NOT SUPPORTED in this field!
#    Envoy Gateway will URL-encode the literal asterisk, breaking authentication.
#
#    MULTI-APP SSO PATTERN (RECOMMENDED - OMIT THIS FIELD):
#    - OMIT this field entirely to use DYNAMIC redirect URL
#    - When omitted, Envoy Gateway uses the request hostname automatically:
#      %REQ(x-forwarded-proto)%://%REQ(:authority)%/oauth2/callback
#      This becomes https://grafana.example.com/oauth2/callback, etc.
#    - Set oidc_cookie_domain to your top-level domain (e.g., "example.com")
#    - Configure Keycloak with WILDCARD redirect URIs: "https://*.example.com/oauth2/callback"
#      (Keycloak DOES support wildcards in its redirect URI configuration)
#    - Result: Single sign-on works across ALL *.example.com apps automatically!
#
#    STATIC REDIRECT URL (alternative - only if you need a single callback URL):
#    - Set to a specific URL like "https://sso.matherly.net/oauth2/callback"
#    - All OIDC callbacks route through this single URL
#
#    The cookie domain enables cross-subdomain session sharing, so users authenticate
#    once and access any protected app without re-authenticating.
#
# oidc_redirect_url: ""  # OMIT for dynamic redirect (recommended)

# -- Cookie domain for SSO session cookies
#    Set to top-level domain to enable SSO across ALL subdomains
#    (REQUIRED for multi-app SSO) / (e.g. "example.com" for *.example.com)
#    When set, a single authentication works for grafana.example.com, app1.example.com, etc.
# oidc_cookie_domain: ""

# -- Cookie SameSite attribute (v1.5+ feature)
#    Controls when cookies are sent with cross-site requests
#    Options: "Strict", "Lax", "None"
#    (OPTIONAL) / (DEFAULT: "Lax" - browser default)
#    NOTE: Not yet in Envoy Gateway v1alpha1 schema - uncomment when supported
# oidc_cookie_samesite: "Lax"

# -- Enable automatic token refresh (v1.6+ feature)
#    When true, tokens are automatically refreshed when they expire
#    NOTE: v1.6+ defaults to true (breaking change from v1.5)
#    Set to false to disable automatic refresh
#    (OPTIONAL) / (DEFAULT: true in v1.6+)
#    NOTE: Not yet in Envoy Gateway v1alpha1 schema - uncomment when supported
# oidc_refresh_token: true

# -- Path that triggers logout flow
#    (OPTIONAL) / (DEFAULT: "/logout")
# oidc_logout_path: "/logout"

# -- OAuth2 scopes to request
#    (OPTIONAL) / (DEFAULT: ["openid", "profile", "email"])
# oidc_scopes:
#   - openid
#   - profile
#   - email

# -- OIDC authorization endpoint (optional override)
#    Auto-discovered from issuer_url if not set
# oidc_authorization_endpoint: ""

# -- OIDC token endpoint (optional override)
#    Auto-discovered from issuer_url if not set
# oidc_token_endpoint: ""

# =============================================================================
# SOCIAL IDENTITY PROVIDERS - Keycloak Identity Federation
# =============================================================================
# Configure social login options (Google, GitHub, Microsoft) in Keycloak.
# When enabled, these IdPs appear as login options on the Keycloak login page.
# Users can authenticate via their existing social accounts.
#
# SETUP WORKFLOW FOR EACH IdP:
#   1. Create OAuth app in the provider's developer console
#   2. Set redirect URI to: https://auth.<your-domain>/realms/<realm>/broker/<alias>/endpoint
#   3. Copy client ID and secret to variables below
#   4. Set *_idp_enabled: true
#   5. Run 'task configure' and 'task reconcile'
#
# REF: docs/research/keycloak-social-identity-providers-integration-jan-2026.md
# REF: https://www.keycloak.org/docs/latest/server_admin/#_identity_broker

# -- Enable Google Identity Provider (OIDC)
#    Console: https://console.cloud.google.com/apis/credentials
#    Callback: https://auth.<domain>/realms/<realm>/broker/google/endpoint
#    (OPTIONAL) / (DEFAULT: false)
# google_idp_enabled: false

# -- Google OAuth client ID
#    (REQUIRED when google_idp_enabled: true)
# google_client_id: ""

# -- Google OAuth client secret (SOPS-encrypted)
#    (REQUIRED when google_idp_enabled: true)
# google_client_secret: ""

# -- Enable GitHub Identity Provider (OAuth2)
#    Console: https://github.com/settings/developers
#    Callback: https://auth.<domain>/realms/<realm>/broker/github/endpoint
#    (OPTIONAL) / (DEFAULT: false)
# github_idp_enabled: false

# -- GitHub OAuth client ID
#    (REQUIRED when github_idp_enabled: true)
# github_client_id: ""

# -- GitHub OAuth client secret (SOPS-encrypted)
#    (REQUIRED when github_idp_enabled: true)
# github_client_secret: ""

# -- Enable Microsoft Entra ID (Azure AD) Identity Provider (OIDC)
#    Console: https://portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps
#    Callback: https://auth.<domain>/realms/<realm>/broker/microsoft/endpoint
#    (OPTIONAL) / (DEFAULT: false)
# microsoft_idp_enabled: false

# -- Microsoft Entra ID application (client) ID
#    (REQUIRED when microsoft_idp_enabled: true)
# microsoft_client_id: ""

# -- Microsoft Entra ID client secret (SOPS-encrypted)
#    (REQUIRED when microsoft_idp_enabled: true)
# microsoft_client_secret: ""

# -- Microsoft tenant ID (Directory ID, "common" for multi-tenant)
#    "common": Allow any Microsoft account (personal or work/school)
#    "<tenant-id>": Restrict to specific Azure AD tenant
#    (OPTIONAL) / (DEFAULT: "common")
# microsoft_tenant_id: "common"

# =============================================================================
# IDENTITY PROVIDER ROLE MAPPERS - Automatic Role Assignment
# =============================================================================
# Configure automatic role assignment based on IdP attributes/claims.
# These mappers run during user login and assign Keycloak roles automatically.
#
# MAPPER TYPES:
#   - Hardcoded Role: Assigns a fixed role to ALL users from an IdP
#   - Claim to Role: Maps specific claim values to roles
#   - Advanced Claim to Role: Regex-based claim matching (Microsoft groups)
#
# ROLE FORMAT: "realm-role-name" or "client-id.client-role-name"
#
# REF: docs/research/keycloak-social-identity-providers-integration-jan-2026.md
# REF: https://www.keycloak.org/docs/latest/server_admin/#_mappers

# -- Google: Assign default role to all Google users
#    Uses "Hardcoded Role" mapper (oidc-hardcoded-role-idp-mapper)
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# google_default_role: ""

# -- Google: Map hosted domain (hd claim) to role
#    Example: Users from "matherly.net" get "domain-user" role
#    Uses "Claim to Role" mapper (oidc-role-idp-mapper)
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# google_domain_role_mapping:
#   domain: "matherly.net"
#   role: "domain-user"

# -- GitHub: Assign default role to all GitHub users
#    Uses "Hardcoded Role" mapper (oidc-hardcoded-role-idp-mapper)
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# github_default_role: ""

# -- GitHub: Map organization membership to role
#    NOTE: Requires adding "read:org" scope to GitHub IdP config
#    GitHub includes org membership in the access token when scope is granted
#    Uses "Claim to Role" mapper with regex matching
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# github_org_role_mapping:
#   org: "my-org"
#   role: "org-member"

# -- Microsoft: Assign default role to all Microsoft users
#    Uses "Hardcoded Role" mapper (oidc-hardcoded-role-idp-mapper)
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# microsoft_default_role: ""

# -- Microsoft: Map Entra ID group ObjectID to role
#    NOTE: Requires enabling "groups" claim in Azure App Registration:
#          Token Configuration → Add optional claim → groups
#    Uses "Advanced Claim to Role" mapper (oidc-advanced-role-idp-mapper)
#    The group_id is the Object ID from Entra ID (UUID format)
#    (OPTIONAL) / (DEFAULT: disabled when empty)
# microsoft_group_role_mappings:
#   - group_id: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
#     role: "admin"
#   - group_id: "yyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy"
#     role: "user"

# =============================================================================
# LITELLM PROXY GATEWAY - Unified AI Model Gateway
# =============================================================================
# LiteLLM provides a unified OpenAI-compatible API for multiple LLM providers.
# Supports Azure OpenAI, Anthropic (via Azure AI), Cohere, and more.
# Features: Cost tracking, rate limiting, caching, observability.
# REF: https://docs.litellm.ai/docs/proxy/quick_start
# REF: docs/research/litellm-proxy-gateway-integration-jan-2026.md
#
# PREREQUISITES:
#   - cnpg_enabled: true (CloudNativePG for PostgreSQL backend)
#   - At least one AI provider API key configured
#
# OPTIONAL INTEGRATIONS:
#   - keycloak_enabled: true → OIDC SSO for admin UI
#   - rustfs_enabled: true → PostgreSQL backups to S3
#   - monitoring_enabled: true → Prometheus metrics
#   - tracing_enabled: true → OpenTelemetry traces to Tempo
#   - Langfuse → External LLM observability platform
#
# SETUP WORKFLOW:
#   1. Enable cnpg_enabled: true (CloudNativePG operator)
#   2. Set litellm_enabled: true and required credentials below
#   3. Configure at least one AI provider (Azure OpenAI, etc.)
#   4. Run 'task configure' and 'task reconcile'
#   5. Access LiteLLM at https://litellm.<your-domain>
#
# SECURITY NOTES:
#   - Master key should start with "sk-" and be at least 32 chars
#   - Salt key used for encrypting sensitive data in database
#   - All secrets are SOPS-encrypted after 'task configure'

# -- Enable LiteLLM Proxy Gateway
#    (OPTIONAL) / (DEFAULT: false)
# litellm_enabled: false

# -- LiteLLM subdomain (creates litellm.<cloudflare_domain>)
#    (OPTIONAL) / (DEFAULT: "litellm")
# litellm_subdomain: "litellm"

# -- Number of LiteLLM replicas
#    (OPTIONAL) / (DEFAULT: 1) / (Range: 1-10)
# litellm_replicas: 1

# -- LiteLLM master API key (SOPS-encrypted)
#    Generate with: echo "sk-$(openssl rand -base64 24 | tr -d '/+=' | head -c 32)"
#    MUST start with "sk-" and be at least 32 characters
#    Used for API authentication and admin access
#    (REQUIRED when litellm_enabled: true)
# litellm_master_key: "sk-"

# -- LiteLLM salt key for database encryption (SOPS-encrypted)
#    Generate with: openssl rand -hex 32
#    Used to encrypt sensitive data stored in PostgreSQL
#    (REQUIRED when litellm_enabled: true)
# litellm_salt_key: ""

# =============================================================================
# LITELLM POSTGRESQL DATABASE (CloudNativePG)
# =============================================================================
# PostgreSQL backend for LiteLLM usage tracking, rate limiting, and team management.
# Deployed via CloudNativePG for automated HA, backups, and monitoring.
# Requires cnpg_enabled: true

# -- PostgreSQL username for LiteLLM
#    (OPTIONAL) / (DEFAULT: "litellm")
# litellm_db_user: "litellm"

# -- PostgreSQL password (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    (REQUIRED when litellm_enabled: true)
# litellm_db_password: ""

# -- PostgreSQL database name
#    (OPTIONAL) / (DEFAULT: "litellm")
# litellm_db_name: "litellm"

# -- Number of PostgreSQL instances (1 for dev, 3 for HA)
#    (OPTIONAL) / (DEFAULT: 1) / (Range: 1-5)
# litellm_db_instances: 1

# -- PostgreSQL storage size
#    (OPTIONAL) / (DEFAULT: "10Gi")
# litellm_storage_size: "10Gi"

# =============================================================================
# LITELLM CACHE - SHARED DRAGONFLY
# =============================================================================
# LiteLLM uses the shared Dragonfly deployment in the cache namespace.
# Requires: dragonfly_enabled: true, dragonfly_acl_enabled: true
# Set dragonfly_litellm_password in the Dragonfly ACL section for authentication.
# LiteLLM keys are prefixed with litellm:* for namespace isolation.
# REF: docs/research/dragonfly-redis-alternative-integration-jan-2026.md

# =============================================================================
# LITELLM OIDC AUTHENTICATION (Keycloak SSO)
# =============================================================================
# Enable SSO for LiteLLM admin UI via Keycloak.
# Requires keycloak_enabled: true

# -- Enable OIDC authentication for LiteLLM
#    When enabled, LiteLLM uses Keycloak for admin UI authentication
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: keycloak_enabled: true)
# litellm_oidc_enabled: false

# -- LiteLLM OIDC client secret (SOPS-encrypted)
#    Generate with: openssl rand -hex 32
#    This secret is automatically configured in Keycloak via realm import
#    (REQUIRED when litellm_oidc_enabled: true)
# litellm_oidc_client_secret: ""

# =============================================================================
# LITELLM POSTGRESQL BACKUPS (requires rustfs_enabled: true)
# =============================================================================
# Uses CloudNativePG barmanObjectStore for continuous WAL archiving.
# The RustFS bucket setup job automatically creates the 'litellm-backups' bucket.
# Credentials must be created via RustFS Console UI (Identity -> Users).
# REQUIRES: rustfs_enabled: true
# REF: docs/ai-context/litellm.md#rustfs-iam-setup-principle-of-least-privilege
# -----------------------------------------------------------------------------

# -- Enable PostgreSQL backups to RustFS
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: rustfs_enabled: true)
# litellm_backup_enabled: false

# -- S3 access key for PostgreSQL backups (SOPS-encrypted)
#    Create policy 'litellm-storage' scoped to litellm-backups bucket
#    Create 'ai-system' group with litellm-storage policy (if not exists)
#    Create user 'litellm-backup' in ai-system group
#    (REQUIRED when litellm_backup_enabled: true)
# litellm_s3_access_key: ""

# -- S3 secret key for PostgreSQL backups (SOPS-encrypted)
#    (REQUIRED when litellm_backup_enabled: true)
# litellm_s3_secret_key: ""

# =============================================================================
# LITELLM OBSERVABILITY
# =============================================================================
# Enable metrics and tracing for LiteLLM.

# -- Enable Prometheus metrics via ServiceMonitor
#    Scrapes /metrics endpoint for cost, latency, and usage metrics
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true)
# litellm_monitoring_enabled: false

# -- Enable OpenTelemetry tracing to Tempo
#    Exports traces via OTLP gRPC to Tempo
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: tracing_enabled: true)
# litellm_tracing_enabled: false

# =============================================================================
# LITELLM LANGFUSE OBSERVABILITY (External)
# =============================================================================
# Langfuse provides LLM-specific observability: prompt analytics, cost tracking,
# trace visualization, and evaluation capabilities.
# REF: https://docs.litellm.ai/docs/observability/langfuse_integration
# REF: docs/research/langfuse-llm-observability-integration-jan-2026.md

# -- Enable Langfuse integration
#    (OPTIONAL) / (DEFAULT: false)
# litellm_langfuse_enabled: false

# -- Langfuse host URL
#    For self-hosted Langfuse (langfuse_enabled: true), use internal cluster address:
#    http://langfuse-web.ai-system.svc.cluster.local:3000
#    For Langfuse Cloud, use: https://cloud.langfuse.com
#    (OPTIONAL) / (DEFAULT: internal cluster URL when langfuse_enabled, cloud otherwise)
# litellm_langfuse_host: "http://langfuse-web.ai-system.svc.cluster.local:3000"

# -- Langfuse public key
#    Get from Langfuse project settings
#    (REQUIRED when litellm_langfuse_enabled: true)
# litellm_langfuse_public_key: ""

# -- Langfuse secret key (SOPS-encrypted)
#    Get from Langfuse project settings
#    (REQUIRED when litellm_langfuse_enabled: true)
# litellm_langfuse_secret_key: ""

# =============================================================================
# LITELLM ALERTING - Slack/Discord Webhook Notifications
# =============================================================================
# Configure alerting for LiteLLM events: slow requests, errors, budget exceeded.
# Uses native LiteLLM alerting callbacks via webhook integrations.
# REF: https://docs.litellm.ai/docs/proxy/alerting

# -- Enable LiteLLM alerting
#    When enabled, LiteLLM sends notifications for configured events
#    (OPTIONAL) / (DEFAULT: false)
# litellm_alerting_enabled: false

# -- Slack webhook URL for alerts (SOPS-encrypted)
#    Create via: Slack App → Incoming Webhooks → Add New Webhook
#    Format: https://hooks.slack.com/services/T.../B.../xxx
#    (OPTIONAL) / (One of slack or discord required when alerting enabled)
# litellm_slack_webhook_url: ""

# -- Discord webhook URL for alerts (SOPS-encrypted)
#    Create via: Server Settings → Integrations → Webhooks → New Webhook
#    Format: https://discord.com/api/webhooks/.../...
#    (OPTIONAL) / (One of slack or discord required when alerting enabled)
# litellm_discord_webhook_url: ""

# -- Slow request threshold in seconds
#    Requests exceeding this duration trigger slow request alerts
#    (OPTIONAL) / (DEFAULT: 300) / (Range: 60-3600)
# litellm_alerting_threshold: 300

# =============================================================================
# LITELLM GUARDRAILS - Content Safety and Security
# =============================================================================
# Enable content filtering, PII masking, and prompt injection detection.
# Guardrails intercept requests/responses to enforce safety policies.
# REF: https://docs.litellm.ai/docs/proxy/guardrails/

# -- Enable LiteLLM built-in guardrails
#    Activates content filtering and moderation checks
#    (OPTIONAL) / (DEFAULT: false)
# litellm_guardrails_enabled: false

# -- Enable Presidio PII masking
#    Uses Microsoft Presidio for detecting and masking PII in prompts
#    Adds Presidio analyzer/anonymizer sidecars to LiteLLM pods
#    (OPTIONAL) / (DEFAULT: false)
# litellm_presidio_enabled: false

# -- Enable prompt injection detection
#    Scans prompts for common injection patterns
#    (OPTIONAL) / (DEFAULT: false)
# litellm_prompt_injection_check: false

# =============================================================================
# AZURE OPENAI API KEYS
# =============================================================================
# Azure OpenAI provides enterprise-grade GPT models with SLA guarantees.
# Configure one or both regions for redundancy.
#
# CONFIGURATION PATTERN:
#   - api_key: SOPS-encrypted secret (from Azure Portal → Keys and Endpoint)
#   - resource_name: Azure resource name (e.g., "my-openai-eastus")
#   - api_version: API version string (defaults provided, override if needed)

# -- Azure OpenAI US East Configuration
#    Get from Azure Portal → Azure OpenAI resource → Keys and Endpoint
#    (OPTIONAL) / (At least one Azure region required when litellm_enabled)
# azure_openai_us_east_api_key: ""
# azure_openai_us_east_resource_name: ""
# azure_openai_us_east_api_version: "2025-01-01-preview"

# -- Azure OpenAI US East 2 Configuration (GPT-5 series, secondary region)
#    (OPTIONAL)
# azure_openai_us_east2_api_key: ""
# azure_openai_us_east2_resource_name: ""
# azure_openai_us_east2_api_version: "2025-04-01-preview"

# =============================================================================
# AZURE AI SERVICES API KEYS AND ENDPOINTS
# =============================================================================
# Azure AI Services provides access to Anthropic Claude and Cohere models.
# These are separate from Azure OpenAI and require Azure AI Services resources.
# Full API base URL is required (not just resource name).
#
# CONFIGURATION PATTERN:
#   - api_key: SOPS-encrypted secret (from Azure Portal → Azure AI Services → Keys)
#   - api_base: Full endpoint URL (e.g., "https://my-ai-services.cognitiveservices.azure.com")

# -- Azure Anthropic API (Claude models via Azure AI Services)
#    (OPTIONAL)
# azure_anthropic_api_key: ""
# azure_anthropic_api_base: ""

# -- Azure Cohere Embed API (embedding models via Azure AI Services)
#    (OPTIONAL)
# azure_cohere_embed_api_key: ""
# azure_cohere_embed_api_base: ""

# -- Azure Cohere Rerank API (reranking models via Azure AI Services)
#    (OPTIONAL)
# azure_cohere_rerank_api_key: ""
# azure_cohere_rerank_api_base: ""

# -- Azure OpenAI Realtime API Base (gpt-realtime models via Azure Cognitive Services)
#    Uses Azure Cognitive Services endpoint for realtime audio/video models
#    (OPTIONAL) Only required if using gpt-realtime or gpt-realtime-mini models
# azure_openai_realtime_api_base: ""

# =============================================================================
# LANGFUSE LLM OBSERVABILITY PLATFORM (Self-Hosted)
# =============================================================================
# Self-hosted Langfuse provides LLM tracing, prompt management, evaluation,
# and cost analytics. Deploys in ai-system namespace alongside LiteLLM.
# REF: https://langfuse.com/self-hosting
# REF: docs/research/langfuse-llm-observability-integration-jan-2026.md
#
# INFRASTRUCTURE DEPENDENCIES:
#   - CloudNativePG (cnpg_enabled: true) - PostgreSQL for transactional data
#   - RustFS (rustfs_enabled: true) - S3 storage for events/media/exports
#   - Dragonfly (dragonfly_enabled: true) - Redis-compatible caching
#   - ClickHouse (bundled) - Analytics database
#
# OPTIONAL INTEGRATIONS:
#   - Keycloak SSO (langfuse_sso_enabled: true)
#   - Prometheus monitoring (langfuse_monitoring_enabled: true)
#   - Tempo tracing (langfuse_tracing_enabled: true)
#
# RUSTFS BUCKETS (create via Console UI port 9001):
#   - langfuse-events: Raw trace event storage
#   - langfuse-media: Multi-modal file uploads
#   - langfuse-exports: Batch data exports
#   - langfuse-postgres-backups: PostgreSQL WAL backups (if backup enabled)

# -- Enable self-hosted Langfuse deployment
#    (OPTIONAL) / (DEFAULT: false)
# langfuse_enabled: false

# -- Langfuse subdomain (creates langfuse.${cloudflare_domain})
#    (OPTIONAL) / (DEFAULT: "langfuse")
# langfuse_subdomain: "langfuse"

# -- NextAuth session secret (256+ entropy)
#    Generate with: openssl rand -base64 32
#    (REQUIRED when langfuse_enabled: true)
# langfuse_nextauth_secret: ""

# -- API key hashing salt (256+ entropy)
#    Generate with: openssl rand -base64 32
#    (REQUIRED when langfuse_enabled: true)
# langfuse_salt: ""

# -- Data encryption key (256-bit hex)
#    Generate with: openssl rand -hex 32
#    (REQUIRED when langfuse_enabled: true)
# langfuse_encryption_key: ""

# -- PostgreSQL password for Langfuse database (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    (REQUIRED when langfuse_enabled: true)
# langfuse_postgres_password: ""

# -- PostgreSQL HA instances (1 for dev, 3+ for production)
#    (OPTIONAL) / (DEFAULT: 1)
# langfuse_postgres_instances: 1

# -- PostgreSQL storage size
#    (OPTIONAL) / (DEFAULT: "10Gi")
# langfuse_postgres_storage: "10Gi"

# -- ClickHouse password for analytics database (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    (REQUIRED when langfuse_enabled: true)
# langfuse_clickhouse_password: ""

# -- ClickHouse storage size
#    (OPTIONAL) / (DEFAULT: "20Gi")
# langfuse_clickhouse_storage: "20Gi"

# -- Enable ClickHouse cluster mode (ON CLUSTER commands)
#    Set to true for multi-node ClickHouse deployments
#    (OPTIONAL) / (DEFAULT: false)
# langfuse_clickhouse_cluster_enabled: false

# -- S3 access key for RustFS (created via RustFS Console)
#    (REQUIRED when langfuse_enabled: true and rustfs_enabled: true)
# langfuse_s3_access_key: ""

# -- S3 secret key for RustFS (SOPS-encrypted)
#    (REQUIRED when langfuse_enabled: true and rustfs_enabled: true)
# langfuse_s3_secret_key: ""

# -- S3 concurrent write connections (for high-throughput)
#    Increase if seeing "@smithy/node-http-handler:WARN - socket usage at capacity"
#    (OPTIONAL) / (DEFAULT: 50)
# langfuse_s3_concurrent_writes: 50

# -- S3 concurrent read connections (for high-throughput)
#    (OPTIONAL) / (DEFAULT: 50)
# langfuse_s3_concurrent_reads: 50

# -- S3 bucket name overrides (if using different bucket names)
#    (OPTIONAL) / (DEFAULT: langfuse-media, langfuse-exports)
# langfuse_media_bucket: "langfuse-media"
# langfuse_export_bucket: "langfuse-exports"

# -- Media upload max file size in bytes
#    (OPTIONAL) / (DEFAULT: 1000000000 = 1GB)
# langfuse_media_max_size: 1000000000

# -- Media presigned URL expiry in seconds
#    (OPTIONAL) / (DEFAULT: 3600 = 1 hour)
# langfuse_media_download_url_expiry: 3600

# -- Enable batch export feature
#    (OPTIONAL) / (DEFAULT: true)
# langfuse_batch_export_enabled: true

# -- Enable PostgreSQL backups to RustFS S3
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: rustfs_enabled: true)
# langfuse_backup_enabled: false

# -- Backup S3 credentials (can reuse langfuse_s3 or use separate)
#    (REQUIRED when langfuse_backup_enabled: true)
# langfuse_backup_s3_access_key: ""
# langfuse_backup_s3_secret_key: ""

# -- Enable Keycloak SSO authentication
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: keycloak_enabled: true)
# langfuse_sso_enabled: false

# -- Keycloak OIDC client secret (SOPS-encrypted)
#    Generate with: openssl rand -hex 32
#    (REQUIRED when langfuse_sso_enabled: true)
# langfuse_keycloak_client_secret: ""

# -- Enable Prometheus metrics via ServiceMonitor
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: monitoring_enabled: true)
# langfuse_monitoring_enabled: false

# -- Enable OpenTelemetry trace export to Tempo
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: tracing_enabled: true)
# langfuse_tracing_enabled: false

# -- Log level (trace, debug, info, warn, error, fatal)
#    (OPTIONAL) / (DEFAULT: "info")
# langfuse_log_level: "info"

# -- Log format (text or json)
#    Use "json" for structured logging in production environments
#    (OPTIONAL) / (DEFAULT: "text")
# langfuse_log_format: "text"

# -- Trace sampling ratio (0.0 to 1.0)
#    (OPTIONAL) / (DEFAULT: "0.1" = 10%)
# langfuse_trace_sampling_ratio: "0.1"

# -- Session max age in seconds
#    Controls how long user sessions remain valid before requiring re-login.
#    (OPTIONAL) / (DEFAULT: 2592000 = 30 days)
# langfuse_session_max_age: 2592000

# =============================================================================
# LANGFUSE CACHING CONFIGURATION
# =============================================================================
# REF: https://langfuse.com/self-hosting/configuration/caching
# -----------------------------------------------------------------------------

# -- Enable API key caching in Redis/Dragonfly
#    Set to false to disable API key caching (useful for debugging)
#    (OPTIONAL) / (DEFAULT: true)
# langfuse_cache_api_key_enabled: true

# -- API key cache TTL in seconds
#    (OPTIONAL) / (DEFAULT: 300 = 5 minutes)
# langfuse_cache_api_key_ttl: 300

# -- Enable prompt caching in Redis/Dragonfly
#    Set to false to disable prompt caching
#    (OPTIONAL) / (DEFAULT: true)
# langfuse_cache_prompt_enabled: true

# -- Prompt cache TTL in seconds
#    (OPTIONAL) / (DEFAULT: 300 = 5 minutes)
# langfuse_cache_prompt_ttl: 300

# =============================================================================
# LANGFUSE AUTHENTICATION CONFIGURATION
# =============================================================================
# REF: https://langfuse.com/self-hosting/security/authentication-and-sso
# -----------------------------------------------------------------------------

# -- Disable username/password authentication (SSO-only mode)
#    Forces all users to authenticate via SSO; disables local password login
#    (OPTIONAL) / (DEFAULT: false)
# langfuse_disable_password_auth: false

# -- Enforce SSO for specific email domains
#    Comma-separated list of domains that must use SSO authentication
#    Example: "example.com,company.org"
#    (OPTIONAL)
# langfuse_sso_domain_enforcement: ""

# -- SMTP connection URL for email notifications (SOPS-encrypted)
#    Format: smtp://user:pass@host:port or smtps://user:pass@host:port
#    Used for password resets, team invitations, and notifications.
#    (OPTIONAL)
# langfuse_smtp_url: ""

# -- Email sender address
#    The "from" address for outgoing emails.
#    (OPTIONAL) / (DEFAULT: noreply@${cloudflare_domain})
# langfuse_email_from: ""

# -- Web service replicas
#    (OPTIONAL) / (DEFAULT: 1)
# langfuse_web_replicas: 1

# -- Worker service replicas
#    (OPTIONAL) / (DEFAULT: 1)
# langfuse_worker_replicas: 1

# -- Langfuse Helm chart version
#    (OPTIONAL) / (DEFAULT: "*" for latest)
# langfuse_chart_version: "*"

# -- Disable new user signups (security hardening)
#    Set to true when using SSO as primary authentication
#    Prevents self-registration; only SSO or admin-created accounts allowed
#    (OPTIONAL) / (DEFAULT: false)
# langfuse_disable_signup: false

# =============================================================================
# LANGFUSE INITIAL ADMIN USER (Headless Initialization)
# =============================================================================
# -----------------------------------------------------------------------------
# Langfuse Headless Initialization (GitOps Bootstrap)
# REF: https://langfuse.com/self-hosting/headless-initialization
# Bootstrap an initial admin account for GitOps/non-interactive deployments.
# When both email and password are configured, Langfuse auto-creates the admin
# on first startup (idempotent - only creates if not exists).
# -----------------------------------------------------------------------------

# -- Initial admin user email address
#    Used for login and password recovery.
#    (OPTIONAL - but required for headless initialization)
# langfuse_init_user_email: "admin@example.com"

# -- Initial admin user display name
#    (OPTIONAL) / (DEFAULT: "Admin")
# langfuse_init_user_name: "Langfuse Admin"

# -- Initial admin user password (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    Minimum 16 characters for security.
#    (OPTIONAL - but required for headless initialization)
# langfuse_init_user_password: ""

# -- Initial organization ID (Required for headless initialization)
#    A unique slug identifier for the organization (lowercase, alphanumeric, hyphens).
#    Example: "my-org", "acme-corp", "matherly-net"
#    This ID uniquely identifies the organization in Langfuse.
#    Cannot be auto-generated - must be explicitly provided.
#    (REQUIRED when using headless initialization)
# langfuse_init_org_id: "my-org"

# -- Initial organization name
#    The admin user is created as OWNER of this organization.
#    (OPTIONAL) / (DEFAULT: cluster_name or "Langfuse")
# langfuse_init_org_name: "My Org"

# =============================================================================
# PROJECT INITIALIZATION (Optional - for immediate API access)
# =============================================================================
# Creates an initial project alongside the organization.
# Useful for GitOps/CI pipelines that need API keys immediately after deployment.
# REF: https://langfuse.com/self-hosting/administration/headless-initialization
# -----------------------------------------------------------------------------

# -- Initial project ID (Required for project initialization)
#    A unique slug identifier for the project (lowercase, alphanumeric, hyphens).
#    Example: "default-project", "llm-traces", "prod-observability"
#    (REQUIRED when using project initialization)
# langfuse_init_project_id: "default-project"

# -- Initial project name
#    Display name for the project in the Langfuse UI.
#    (OPTIONAL) / (DEFAULT: langfuse_init_project_id)
# langfuse_init_project_name: "Default Project"

# -- Data retention period in days
#    How long to retain trace data. Leave unset for indefinite retention.
#    Valid range: 1-3650 days (10 years max)
#    (OPTIONAL) / (DEFAULT: indefinite)
# langfuse_init_project_retention: 90

# -- Project public API key (Required for project initialization)
#    Format: lf_pk_<random_string>
#    Generate with: echo "lf_pk_$(openssl rand -hex 16)"
#    This key is used for trace ingestion (can be exposed to clients).
#    (REQUIRED when using project initialization)
# langfuse_init_project_public_key: "lf_pk_abc123def456"

# -- Project secret API key (Required for project initialization, SOPS-encrypted)
#    Format: lf_sk_<random_string>
#    Generate with: echo "lf_sk_$(openssl rand -hex 16)"
#    This key is used for API authentication (keep secret!).
#    (REQUIRED when using project initialization)
# langfuse_init_project_secret_key: "lf_sk_xyz789ghi012"

# =============================================================================
# LANGFUSE AUTO-PROVISIONING (Default Access for New SSO Users)
# =============================================================================
# -----------------------------------------------------------------------------
# Langfuse Auto-Provisioning (SSO Default Roles)
# REF: https://langfuse.com/docs/rbac
# REF: https://langfuse.com/self-hosting/automated-provisioning
# Configure default roles for users created via SSO (Keycloak OIDC).
# These apply when a user logs in via SSO for the first time.
# -----------------------------------------------------------------------------

# -- Default organization ID for new SSO users
#    Organization where new SSO users are automatically provisioned
#    If not set, defaults to langfuse_init_org_id (if configured)
#    (OPTIONAL) / (DEFAULT: langfuse_init_org_id)
# langfuse_default_org_id: "my-org"

# -- Default organization role for new users via SSO
#    Roles: OWNER, ADMIN, MEMBER, VIEWER, NONE (no org access)
#    VIEWER = read-only access to organization and projects
#    NONE = must be explicitly granted project-level access
#    (OPTIONAL) / (DEFAULT: not set - users must be manually added)
# langfuse_default_org_role: "VIEWER"

# -- Default project ID for new SSO users
#    Project where new SSO users are automatically provisioned
#    If not set, defaults to langfuse_init_project_id (if configured)
#    (OPTIONAL) / (DEFAULT: langfuse_init_project_id)
# langfuse_default_project_id: "default-project"

# -- Default project role for new users via SSO
#    Roles: OWNER, ADMIN, MEMBER, VIEWER
#    When set, new users get this role on all projects in default org
#    (OPTIONAL) / (DEFAULT: not set - no project access by default)
# langfuse_default_project_role: "VIEWER"

# =============================================================================
# LANGFUSE SCIM ROLE SYNC (Keycloak → Langfuse)
# =============================================================================
# Synchronizes user roles from Keycloak to Langfuse via SCIM API.
# Since Langfuse doesn't natively support OIDC role claims, this CronJob
# periodically syncs roles from Keycloak to Langfuse.
# REF: docs/research/langfuse-scim-role-sync-implementation-jan-2026.md
# REQUIRES: langfuse_enabled: true, keycloak_enabled: true
# -----------------------------------------------------------------------------

# -- Enable SCIM role sync from Keycloak
#    When enabled, a CronJob syncs Keycloak roles to Langfuse via SCIM API
#    NOTE: SCIM API requires Organization API Keys which require Langfuse Enterprise license
#    REF: docs/research/langfuse-scim-role-sync-implementation-jan-2026.md
#    (OPTIONAL) / (DEFAULT: false)
# langfuse_scim_sync_enabled: false
# langfuse_scim_sync_schedule: "*/5 * * * *"
# langfuse_scim_public_key: ""
# langfuse_scim_secret_key: ""
# langfuse_sync_keycloak_client_id: "langfuse-sync"
# langfuse_sync_keycloak_client_secret: ""
# langfuse_role_mapping:
#   admin: "ADMIN"
#   operator: "MEMBER"
#   developer: "MEMBER"
#   default: "VIEWER"

# =============================================================================
# OBOT MCP GATEWAY - AI Agent Platform with MCP Server Hosting
# =============================================================================
# Obot provides an AI agent platform with Model Context Protocol (MCP) server
# orchestration for enhanced AI capabilities. This deployment uses the custom
# jrmatherly/obot-entraid fork which adds Keycloak authentication support.
# REF: https://docs.obot.ai/
# REF: https://github.com/jrmatherly/obot-entraid
# REF: docs/research/obot-mcp-gateway-integration-jan-2026.md
# REQUIRES: cnpg_enabled: true (PostgreSQL with pgvector)
# -----------------------------------------------------------------------------
#
# ARCHITECTURE:
#   - Main Obot pod runs in ai-system namespace
#   - MCP servers spawn dynamically in dedicated obot-mcp namespace
#   - PostgreSQL 17+ with pgvector for AI/ML workloads
#   - Keycloak SSO via custom auth provider (OBOT_KEYCLOAK_AUTH_PROVIDER_*)
#   - Optional integration with internal LiteLLM for model routing
#
# DEPENDENCIES:
#   - cnpg_enabled: true (CloudNativePG operator for PostgreSQL)
#   - cnpg_pgvector_enabled: true (pgvector extension for embeddings)
#   - keycloak_enabled: true (for Keycloak SSO, optional but recommended)
#   - litellm_enabled: true (for model gateway integration, optional)
#   - rustfs_enabled: true (for PostgreSQL backups, optional)
#
# SETUP WORKFLOW:
#   1. Enable cnpg_enabled: true and cnpg_pgvector_enabled: true
#   2. Set obot_enabled: true and required credentials below
#   3. Configure Keycloak SSO (recommended for production)
#   4. Run 'task configure' and 'task reconcile'
#   5. Access Obot at https://obot.<your-domain>

# -- Enable Obot MCP Gateway
#    (OPTIONAL) / (DEFAULT: false)
# obot_enabled: false

# -- Obot subdomain (creates obot.<cloudflare_domain>)
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_subdomain: "obot"

# -- Obot image version tag
#    Uses jrmatherly/obot-entraid fork with Keycloak auth provider
#    (OPTIONAL) / (DEFAULT: "0.2.32")
# obot_version: "0.2.32"

# -- Number of Obot pod replicas
#    (OPTIONAL) / (DEFAULT: 1)
# obot_replicas: 1

# =============================================================================
# OBOT POSTGRESQL DATABASE (CloudNativePG with pgvector)
# =============================================================================
# Obot requires PostgreSQL 17+ with pgvector extension for AI/ML workloads.
# Uses CloudNativePG operator for automated HA and backup management.

# -- PostgreSQL password (SOPS-encrypted)
#    Generate with: openssl rand -base64 24
#    (REQUIRED when obot_enabled: true)
# obot_db_password: ""

# -- PostgreSQL username
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_postgres_user: "obot"

# -- PostgreSQL database name
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_postgres_db: "obot"

# -- Number of PostgreSQL replicas (1=dev, 3+=production)
#    (OPTIONAL) / (DEFAULT: 1)
# obot_postgresql_replicas: 1

# -- PostgreSQL PVC storage size
#    (OPTIONAL) / (DEFAULT: "10Gi")
# obot_postgresql_storage_size: "10Gi"

# -- Obot data storage size (for file uploads, etc.)
#    (OPTIONAL) / (DEFAULT: "20Gi")
# obot_storage_size: "20Gi"

# =============================================================================
# OBOT ENCRYPTION
# =============================================================================
# Obot uses encryption for data at rest. This key must be base64-encoded 32 bytes.

# -- Data at rest encryption key (SOPS-encrypted)
#    Generate with: openssl rand -base64 32
#    (REQUIRED when obot_enabled: true)
# obot_encryption_key: ""

# -- Bootstrap token for initial platform setup (SOPS-encrypted)
#    Used for API authentication before OIDC is configured
#    Generate with: openssl rand -hex 32
#    (OPTIONAL)
# obot_bootstrap_token: ""

# =============================================================================
# OBOT KEYCLOAK SSO (requires keycloak_enabled: true)
# =============================================================================
# Uses custom Keycloak authentication provider from jrmatherly/obot-entraid fork.
# Configures OBOT_KEYCLOAK_AUTH_PROVIDER_* environment variables automatically.
# REF: https://github.com/jrmatherly/obot-entraid/tree/main/tools/keycloak-auth-provider
# REQUIRES: keycloak_enabled: true
# -----------------------------------------------------------------------------

# -- Enable Keycloak SSO authentication
#    When enabled, creates 'obot' client in Keycloak realm
#    (OPTIONAL) / (DEFAULT: false)
# obot_keycloak_enabled: false

# -- OIDC client ID (registered in Keycloak)
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_keycloak_client_id: "obot"

# -- OIDC client secret (SOPS-encrypted)
#    Generate in Keycloak or with: openssl rand -hex 32
#    (REQUIRED when obot_keycloak_enabled: true)
# obot_keycloak_client_secret: ""

# -- Cookie encryption secret (SOPS-encrypted)
#    Generate with: openssl rand -base64 32
#    Must be at least 32 characters
#    (REQUIRED when obot_keycloak_enabled: true)
# obot_keycloak_cookie_secret: ""

# -- Allowed groups (comma-separated, optional)
#    Restricts access to users in specific Keycloak groups
#    Leave empty to allow all authenticated users
#    (OPTIONAL) / (e.g. "obot-users,obot-admins")
# obot_keycloak_allowed_groups: ""

# -- Allowed roles (comma-separated, optional)
#    Restricts access to users with specific Keycloak roles
#    Leave empty to allow all authenticated users
#    (OPTIONAL) / (e.g. "obot-user,obot-admin")
# obot_keycloak_allowed_roles: ""

# =============================================================================
# OBOT MCP NAMESPACE CONFIGURATION
# =============================================================================
# MCP servers spawn dynamically in a dedicated namespace with resource quotas
# and network isolation. Pod Security Standards are set to 'restricted'.
# -----------------------------------------------------------------------------

# -- MCP server namespace name
#    (OPTIONAL) / (DEFAULT: "obot-mcp")
# obot_mcp_namespace: "obot-mcp"

# -- Total CPU requests quota for MCP namespace
#    (OPTIONAL) / (DEFAULT: "4")
# obot_mcp_cpu_requests_quota: "4"

# -- Total CPU limits quota for MCP namespace
#    (OPTIONAL) / (DEFAULT: "8")
# obot_mcp_cpu_limits_quota: "8"

# -- Total memory requests quota for MCP namespace
#    (OPTIONAL) / (DEFAULT: "8Gi")
# obot_mcp_memory_requests_quota: "8Gi"

# -- Total memory limits quota for MCP namespace
#    (OPTIONAL) / (DEFAULT: "16Gi")
# obot_mcp_memory_limits_quota: "16Gi"

# -- Maximum number of MCP server pods
#    (OPTIONAL) / (DEFAULT: "20")
# obot_mcp_max_pods: "20"

# -- Default CPU request per MCP container
#    (OPTIONAL) / (DEFAULT: "100m")
# obot_mcp_default_cpu_request: "100m"

# -- Default CPU limit per MCP container
#    (OPTIONAL) / (DEFAULT: "500m")
# obot_mcp_default_cpu_limit: "500m"

# -- Default memory request per MCP container
#    (OPTIONAL) / (DEFAULT: "256Mi")
# obot_mcp_default_memory_request: "256Mi"

# -- Default memory limit per MCP container
#    (OPTIONAL) / (DEFAULT: "512Mi")
# obot_mcp_default_memory_limit: "512Mi"

# -- Maximum CPU per MCP container
#    (OPTIONAL) / (DEFAULT: "1000m")
# obot_mcp_max_cpu: "1000m"

# -- Maximum memory per MCP container
#    (OPTIONAL) / (DEFAULT: "1Gi")
# obot_mcp_max_memory: "1Gi"

# =============================================================================
# OBOT POSTGRESQL BACKUPS (requires rustfs_enabled: true)
# =============================================================================
# Uses CloudNativePG barmanObjectStore for continuous WAL archiving.
# The RustFS bucket setup job automatically creates the 'obot-postgres-backups' bucket.
# Credentials must be created via RustFS Console UI (Identity -> Users).
# REQUIRES: rustfs_enabled: true
# REF: docs/ai-context/obot.md#rustfs-iam-setup-principle-of-least-privilege
# -----------------------------------------------------------------------------

# -- S3 access key for PostgreSQL backups (SOPS-encrypted)
#    Create policy 'obot-storage' scoped to obot-postgres-backups bucket
#    Create 'ai-system' group with obot-storage policy (if not exists)
#    Create user 'obot-backup' in ai-system group
#    (REQUIRED when obot_enabled and rustfs_enabled: true)
# obot_s3_access_key: ""

# -- S3 secret key for PostgreSQL backups (SOPS-encrypted)
#    (REQUIRED when obot_enabled and rustfs_enabled: true)
# obot_s3_secret_key: ""

# =============================================================================
# OBOT AUDIT LOG EXPORT CONFIGURATION
# =============================================================================
# Export audit logs to S3-compatible storage for compliance and long-term retention.
# Configure via Obot UI: Admin Settings → Audit Logs → Export Audit Logs
# REQUIRES: rustfs_enabled: true
# REF: docs/ai-context/obot.md (Audit Log Export section)
# -----------------------------------------------------------------------------

# -- S3 access key for audit log export
#    Bucket: obot-audit-logs (created by RustFS setup job)
#    Policy: Create 'obot-audit-storage' policy scoped to obot-audit-logs bucket
#    Create 'obot-audit' user in ai-system group
#    (REQUIRED when obot_audit_logs_enabled and rustfs_enabled: true)
# obot_audit_s3_access_key: ""

# -- S3 secret key for audit log export (SOPS-encrypted)
#    (REQUIRED when obot_audit_logs_enabled and rustfs_enabled: true)
# obot_audit_s3_secret_key: ""

# =============================================================================
# OBOT OBSERVABILITY CONFIGURATION
# =============================================================================
# Optional monitoring and tracing integration.
# REQUIRES: monitoring_enabled: true
# REQUIRES: tracing_enabled: true
# -----------------------------------------------------------------------------

# -- Enable Prometheus ServiceMonitor and Grafana dashboards
#    Requires monitoring_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# obot_monitoring_enabled: false

# -- Enable OpenTelemetry tracing export to Tempo
#    REQUIRES: tracing_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# obot_tracing_enabled: false

# =============================================================================
# OBOT LITELLM INTEGRATION
# =============================================================================
# Use internal LiteLLM as the model gateway for Obot AI capabilities.

# -- Enable LiteLLM integration
#    Routes Obot model requests through internal LiteLLM proxy
#    Requires litellm_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# obot_litellm_enabled: false

# =============================================================================
# HEADLAMP - Kubernetes Web UI
# =============================================================================
# Headlamp provides a modern, user-friendly web interface for Kubernetes cluster
# management with OIDC authentication and RBAC support.
# REF: https://headlamp.dev/
# REF: https://headlamp.dev/docs/latest/installation/in-cluster/oidc/
# REQUIRES: keycloak_enabled: true (for OIDC authentication)
# -----------------------------------------------------------------------------

# -- Enable Headlamp deployment
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: keycloak_enabled: true)
# headlamp_enabled: false

# -- Headlamp subdomain (creates headlamp.${cloudflare_domain})
#    (OPTIONAL) / (DEFAULT: "headlamp")
# headlamp_hostname: "headlamp"

# -- Headlamp version (image tag)
#    (OPTIONAL) / (DEFAULT: "0.39.0")
# headlamp_version: "0.39.0"

# -- Headlamp Helm chart version
#    (OPTIONAL) / (DEFAULT: "0.39.0")
# headlamp_chart_version: "0.39.0"

# -- Number of Headlamp replicas
#    (OPTIONAL) / (DEFAULT: 2)
# headlamp_replicas: 2

# -- OIDC client ID (registered in Keycloak)
#    (OPTIONAL) / (DEFAULT: "headlamp")
# headlamp_oidc_client_id: "headlamp"

# -- OIDC client secret (SOPS-encrypted)
#    Generate with: openssl rand -hex 32
#    (REQUIRED when headlamp_enabled: true)
# headlamp_oidc_client_secret: ""

# =============================================================================
# KUBERNETES API SERVER OIDC AUTHENTICATION
# =============================================================================
# Enable OIDC authentication on Kubernetes API Server for user authentication
# via Keycloak tokens. Creates a dedicated "kubernetes" client in Keycloak for
# API Server token validation.
# Used by: Headlamp, kubectl with oidc-login plugin, kubelogin, and future tools
# REF: docs/research/kubernetes-api-server-oidc-authentication-jan-2026.md
# REQUIRES: keycloak_enabled: true
# -----------------------------------------------------------------------------

# -- Enable Kubernetes API Server OIDC authentication
#    Configures kube-apiserver with OIDC provider settings
#    (OPTIONAL) / (DEFAULT: false) / (REQUIRES: keycloak_enabled: true)
# kubernetes_oidc_enabled: false

# -- OIDC client ID for Kubernetes API Server token validation
#    This is the audience (aud) claim expected in ID tokens
#    (OPTIONAL) / (DEFAULT: "kubernetes")
# kubernetes_oidc_client_id: "kubernetes"

# -- OIDC client secret for the Kubernetes client (SOPS-encrypted)
#    Used for token introspection and client authentication
#    Generate with: openssl rand -hex 32
#    (REQUIRED when kubernetes_oidc_enabled: true)
# kubernetes_oidc_client_secret: ""

# -- OIDC username claim to use for Kubernetes user identity
#    Common values: "email", "preferred_username", "sub"
#    (OPTIONAL) / (DEFAULT: "email")
# kubernetes_oidc_username_claim: "email"

# -- OIDC username prefix to avoid conflicts with other auth methods
#    Prefixes all OIDC usernames (e.g., "oidc:user@example.com")
#    Set to "-" to disable prefixing
#    (OPTIONAL) / (DEFAULT: "oidc:")
# kubernetes_oidc_username_prefix: "oidc:"

# -- OIDC groups claim to use for Kubernetes RBAC group membership
#    Keycloak groups mapper must be configured on the client
#    (OPTIONAL) / (DEFAULT: "groups")
# kubernetes_oidc_groups_claim: "groups"

# -- OIDC groups prefix to avoid conflicts with other auth methods
#    Prefixes all OIDC groups (e.g., "oidc:admin")
#    (OPTIONAL) / (DEFAULT: "oidc:")
# kubernetes_oidc_groups_prefix: "oidc:"

# -- OIDC signing algorithms accepted by API Server
#    Keycloak uses RS256 by default for token signing
#    (OPTIONAL) / (DEFAULT: "RS256")
# kubernetes_oidc_signing_algs: "RS256"

# =============================================================================
# VOLSYNC PVC BACKUP - Automated PVC backups with restic to S3
# =============================================================================
# VolSync provides restic-based PVC backups to S3-compatible storage.
# Enables point-in-time recovery for stateful applications.
# REF: https://volsync.readthedocs.io/en/stable/
# REF: docs/guides/k8s-at-home-remaining-implementation.md

# -- Enable VolSync PVC backup
#    (OPTIONAL) / (DEFAULT: false)
# volsync_enabled: false

# -- S3-compatible endpoint for backups (Cloudflare R2 recommended)
#    (OPTIONAL) / (e.g. "https://<account-id>.r2.cloudflarestorage.com")
# volsync_s3_endpoint: ""

# -- S3 bucket name for VolSync backups
#    (OPTIONAL) / (e.g. "cluster-pvc-backups")
# volsync_s3_bucket: ""

# -- Restic repository password for encryption
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# volsync_restic_password: ""

# -- Backup schedule (cron format)
#    (OPTIONAL) / (DEFAULT: "0 */6 * * *" - every 6 hours)
# volsync_schedule: "0 */6 * * *"

# -- Copy method for creating backups: "Clone" or "Snapshot"
#    Clone: Works with any CSI driver supporting volume cloning (Proxmox CSI)
#    Snapshot: Requires CSI driver with VolumeSnapshot support
#    (OPTIONAL) / (DEFAULT: "Clone")
# volsync_copy_method: "Clone"

# -- Daily backup retention count
#    (OPTIONAL) / (DEFAULT: 7)
# volsync_retain_daily: 7

# -- Weekly backup retention count
#    (OPTIONAL) / (DEFAULT: 4)
# volsync_retain_weekly: 4

# -- Monthly backup retention count
#    (OPTIONAL) / (DEFAULT: 3)
# volsync_retain_monthly: 3

# =============================================================================
# GLOBAL VM DEFAULTS (OpenTofu/Proxmox) - Optional for VM deployments
# =============================================================================
# -- Global VM resource defaults (fallback for all nodes)
#    Can be overridden by role-specific defaults or per-node in nodes.yaml
#    Fallback chain: per-node -> role-defaults -> global-defaults

# proxmox_vm_defaults:
#   cores: 4           # CPU cores
#   sockets: 1         # CPU sockets
#   memory: 8192       # Memory in MB
#   disk_size: 128     # Disk size in GB
#
# -- Controller node VM defaults (optimized for etcd and control plane)
#    Controllers run etcd, API server, scheduler, and controller-manager
#    When allowSchedulingOnControlPlanes: false (default), no workloads run here
#    Fallback chain: per-node -> controller-defaults -> global-defaults
# proxmox_vm_controller_defaults:
#   cores: 4           # CPU cores (etcd is single-threaded, 4 is plenty)
#   sockets: 1         # CPU sockets
#   memory: 8192       # Memory in MB (8GB sufficient for control plane)
#   disk_size: 64      # Disk size in GB (etcd only, no workloads)
#
# -- Worker node VM defaults (optimized for running workloads)
#    Workers run application pods, require more resources
#    Fallback chain: per-node -> worker-defaults -> global-defaults
# proxmox_vm_worker_defaults:
#   cores: 8           # CPU cores (more for workload scheduling)
#   sockets: 1         # CPU sockets
#   memory: 16384      # Memory in MB (16GB for application pods)
#   disk_size: 256     # Disk size in GB (container images + workloads)
#
# -- Advanced VM settings (Talos-optimized defaults)
# proxmox_vm_advanced:
#   bios: "ovmf"              # UEFI boot (required for Talos)
#   machine: "q35"            # Modern chipset
#   cpu_type: "host"          # CPU type (host = passthrough)
#   scsi_hw: "virtio-scsi-pci"# SCSI controller
#   balloon: 0                # Memory ballooning disabled (K8s)
#   numa: true                # NUMA enabled
#   qemu_agent: true          # QEMU guest agent
#   net_queues: 4             # Multi-queue networking
#   disk_discard: true        # Enable TRIM/discard
#   disk_ssd: true            # SSD emulation
#   tags: ["kubernetes", "linux", "talos"]  # VM tags
#   # Network configuration
#   network_bridge: "vmbr0"   # Proxmox bridge interface for VM networking
#   # Guest OS configuration
#   ostype: "l26"             # Linux 2.6/3.x/4.x/5.x/6.x kernel
#   # Storage flags (Talos-optimized: immutable OS, K8s handles HA)
#   disk_backup: false        # Exclude from Proxmox backup jobs
#   disk_replicate: false     # Disable Proxmox replication
