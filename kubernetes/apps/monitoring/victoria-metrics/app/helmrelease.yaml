---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: victoria-metrics-k8s-stack
spec:
  chartRef:
    kind: OCIRepository
    name: victoria-metrics-k8s-stack
  interval: 1h
  values:
    # VictoriaMetrics Single (lightweight, recommended for homelab)
    vmsingle:
      enabled: true
      spec:
        retentionPeriod: "7d"
        storage:
          storageClassName: "proxmox-zfs"
          resources:
            requests:
              storage: "50Gi"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            memory: 1Gi
        # Health probes for reliability
        readinessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 5
          periodSeconds: 15
        livenessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5

    # VMAgent for scraping
    vmagent:
      enabled: true
      spec:
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            memory: 256Mi
        # Health probes for reliability
        readinessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 5
          periodSeconds: 15
        livenessProbe:
          httpGet:
            path: /health
            port: 8429
          initialDelaySeconds: 30
          periodSeconds: 30

    # Grafana
    grafana:
      enabled: true
      admin:
        existingSecret: grafana-admin-secret
        userKey: admin-user
        passwordKey: admin-password
      ingress:
        enabled: false
      persistence:
        enabled: true
        storageClassName: "proxmox-zfs"
        size: 5Gi
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        limits:
          memory: 512Mi
      # Health probes for reliability
      readinessProbe:
        httpGet:
          path: /api/health
          port: 3000
        initialDelaySeconds: 10
        periodSeconds: 10
      livenessProbe:
        httpGet:
          path: /api/health
          port: 3000
        initialDelaySeconds: 30
        periodSeconds: 30
        timeoutSeconds: 5
      # Sidecar disabled - using grafana.dashboards for provisioning instead
      # The victoria-metrics chart doesn't allow both sidecar and dashboards simultaneously
      sidecar:
        dashboards:
          enabled: false
      # Dashboard provisioning
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: infrastructure
              folder: Infrastructure
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/infrastructure
            - name: network
              folder: Network
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/network
            - name: gitops
              folder: GitOps
              type: file
              disableDeletion: false
              editable: true
              options:
                path: /var/lib/grafana/dashboards/gitops
      dashboards:
        infrastructure:
          # Kubernetes Core (dotdc collection)
          kubernetes-global:
            gnetId: 15757
            revision: 43
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          kubernetes-nodes:
            gnetId: 15759
            revision: 32
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          kubernetes-pods:
            gnetId: 15760
            revision: 36
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Node metrics
          node-exporter-full:
            gnetId: 1860
            revision: 37
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Control plane
          kubernetes-etcd:
            gnetId: 20330
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # CoreDNS
          kubernetes-coredns:
            gnetId: 15762
            revision: 18
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # cert-manager (uses Datasource variable, not DS_PROMETHEUS)
          cert-manager:
            gnetId: 11001
            revision: 1
            datasource:
              - name: Datasource
                value: VictoriaMetrics
        network:
          # Cilium Agent (BPF operations, API latency, forwarding stats)
          cilium-agent:
            gnetId: 16611
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Operator (IPAM, node management)
          cilium-operator:
            gnetId: 16612
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Hubble (flows, drops, DNS, HTTP, TCP)
          cilium-hubble:
            gnetId: 16613
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Network Policy Verdicts (policy enforcement tracking)
          cilium-policy-verdicts:
            gnetId: 18015
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Cilium Network Monitoring (endpoints, BPF maps, connectivity)
          cilium-network-monitoring:
            gnetId: 24056
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Envoy Gateway
          envoy-gateway:
            gnetId: 24460
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics
          # Envoy Proxy (uses DS_PROMETHEUS-04 variable)
          envoy-proxy:
            gnetId: 21329
            revision: 1
            datasource:
              - name: DS_PROMETHEUS-04
                value: VictoriaMetrics
        gitops:
          flux2:
            gnetId: 16714
            revision: 1
            datasource:
              - name: DS_PROMETHEUS
                value: VictoriaMetrics

    defaultDatasources:
      extra:
        - name: Prometheus
          type: prometheus
          url: http://vmsingle-victoria-metrics-k8s-stack.monitoring.svc:8429
          access: proxy
          isDefault: false
        - name: Loki
          type: loki
          url: http://loki:3100
          access: proxy
          isDefault: false
          jsonData:
            maxLines: 1000
        - name: Tempo
          type: tempo
          url: http://tempo:3200
          access: proxy
          isDefault: false
          jsonData:
            tracesToLogs:
              datasourceUid: loki
              tags: ['namespace', 'pod']
              mappedTags: [{ key: 'service.name', value: 'service' }]
              mapTagNamesEnabled: true
              filterByTraceID: true
              filterBySpanID: true
            tracesToMetrics:
              datasourceUid: VictoriaMetrics
              tags: [{ key: 'service.name', value: 'service' }]
              queries:
                - name: 'Request Rate'
                  query: 'sum(rate(traces_spanmetrics_calls_total{$$__tags}[5m]))'
            serviceMap:
              datasourceUid: VictoriaMetrics
            nodeGraph:
              enabled: true
            search:
              hide: false
            lokiSearch:
              datasourceUid: loki

    # AlertManager
    alertmanager:
      enabled: true
      spec:
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            memory: 128Mi
        # Health probes for reliability
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 10
          periodSeconds: 30
      config:
        global:
          resolve_timeout: 5m
        route:
          group_by: ['alertname', 'namespace', 'severity']
          group_wait: 30s
          group_interval: 5m
          repeat_interval: 12h
          receiver: 'null'
          routes:
            - match:
                alertname: Watchdog
              receiver: 'null'
            - match:
                severity: critical
              receiver: 'null'
        receivers:
          - name: 'null'

    # Node Exporter
    prometheus-node-exporter:
      enabled: true
      resources:
        requests:
          cpu: 20m
          memory: 32Mi
        limits:
          memory: 64Mi

    # kube-state-metrics
    kube-state-metrics:
      enabled: true
      resources:
        requests:
          cpu: 20m
          memory: 64Mi
        limits:
          memory: 128Mi

    # kubelet scraping
    kubelet:
      enabled: true
      spec:
        # For Talos Linux
        metricRelabelConfigs:
          - action: labeldrop
            regex: (uid)
          - action: labeldrop
            regex: (id|name)
          - action: drop
            source_labels: ["__name__"]
            regex: (rest_client_request_duration_seconds_bucket|rest_client_request_duration_seconds_sum|rest_client_request_duration_seconds_count)

    # etcd monitoring - Talos exposes metrics on HTTP port 2381
    # Ref: https://docs.siderolabs.com/kubernetes-guides/monitoring-and-observability/etcd-metrics
    kubeEtcd:
      enabled: true
      endpoints:
        - 192.168.22.101
        - 192.168.22.102
        - 192.168.22.103
      service:
        enabled: true
        port: 2381
        targetPort: 2381
      vmScrape:
        spec:
          endpoints:
            - port: http-metrics
              scheme: http

    # API Server
    kubeApiServer:
      enabled: true

    # Controller Manager - Talos Linux binds to 0.0.0.0 but certs only valid for localhost
    # Ref: https://github.com/VictoriaMetrics/VictoriaMetrics/issues/6476
    kubeControllerManager:
      enabled: true
      vmScrape:
        spec:
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              port: http-metrics
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                serverName: localhost
                insecureSkipVerify: true

    # Scheduler - Talos Linux binds to 0.0.0.0 but certs only valid for 127.0.0.1
    # Ref: https://github.com/VictoriaMetrics/VictoriaMetrics/issues/6476
    kubeScheduler:
      enabled: true
      vmScrape:
        spec:
          endpoints:
            - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
              port: http-metrics
              scheme: https
              tlsConfig:
                caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                serverName: "127.0.0.1"
                insecureSkipVerify: true
