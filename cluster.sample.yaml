# yaml-language-server: $schema=./.taskfiles/template/resources/cluster.schema.json
---
# -- The network CIDR for the nodes.
# (REQUIRED) / (e.g. 192.168.1.0/24)
node_cidr: ""

# -- DNS servers to use for the cluster.
#    (OPTIONAL) / (DEFAULT: ["1.1.1.1", "1.0.0.1"]) / (Cloudflare DNS)
# node_dns_servers: []

# -- NTP servers to use for the cluster.
#    (OPTIONAL) / (DEFAULT: ["162.159.200.1", "162.159.200.123"]) / (Cloudflare NTP)
# node_ntp_servers: []

# -- The default gateway for the nodes.
#    (OPTIONAL) / (DEFAULT: the first IP in the node_cidr)
# node_default_gateway: ""

# -- Attach a vlan tag to the Talos nodes. Not needed if ports on your switch are tagged or you are not using VLANs.
#    (OPTIONAL) / (REF: https://www.talos.dev/latest/advanced/advanced-networking/#vlans)
# node_vlan_tag: ""

# -- The IP address of the Kube API.
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cluster_api_addr: ""

# -- Additional SANs to add to the Kube API cert. This is useful if you want to call the Kube API by hostname rather than IP
#    (OPTIONAL) / (e.g. ["mycluster.example.com"])
# cluster_api_tls_sans: []

# -- The pod CIDR for the cluster, this must NOT overlap with any existing networks and should be a /16 (64K IPs).
#    (OPTIONAL) / (DEFAULT: "10.42.0.0/16")
# cluster_pod_cidr: ""

# -- The service CIDR for the cluster, this must NOT overlap with any existing networks and should be a /16 (64K IPs).
#    (OPTIONAL) / (DEFAULT: "10.43.0.0/16")
# cluster_svc_cidr: ""

# -- The Load balancer IP for k8s_gateway (split DNS for internal resolution)
#    (CONDITIONAL) / Required ONLY when NOT using UniFi DNS integration
#    When unifi_host and unifi_api_key are set, k8s-gateway is replaced by
#    external-dns-unifi and this setting is ignored.
#    (NOTE: Choose an unused IP in node_cidr if using k8s_gateway)
# cluster_dns_gateway_addr: ""

# -- The Load balancer IP for the internal gateway
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cluster_gateway_addr: ""

# -- GitHub repository
#    (REQUIRED) / (e.g. "onedr0p/cluster-template")
repository_name: ""

# -- GitHub repository branch
#    (OPTIONAL) / (DEFAULT: "main")
# repository_branch: ""

# -- Repository visibility (public or private)
#    (OPTIONAL) / (DEFAULT: "public") / (NOTE: See the README for information when set private)
# repository_visibility: ""

# -- Domain you wish to use from your Cloudflare account
#    (REQUIRED) / (e.g. "example.com")
cloudflare_domain: ""

# -- API Token for Cloudflare with the 'Zone:DNS:Edit' and 'Account:Cloudflare Tunnel:Read' permissions
#    (REQUIRED) (NOTE: See the README for information on creating this)
cloudflare_token: ""

# -- The Load balancer IP for the external gateway
#    (REQUIRED) / (NOTE: Choose an unused IP in node_cidr)
cloudflare_gateway_addr: ""
# -- The load balancer mode for cilium.
#    (OPTIONAL) / (DEFAULT: "dsr") / (NOTE: accepted values are 'dsr' or 'snat') / (REF: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/)
# cilium_loadbalancer_mode: ""

# =============================================================================
# CILIUM BGP CONFIGURATION - Optional for multi-VLAN environments
# =============================================================================
# Enable BGP peering between Cilium and your router for dynamic routing.
# This allows LoadBalancer IPs to be advertised via BGP instead of L2/ARP.
#
# When to use BGP:
# - Multi-VLAN environment requiring cross-subnet service access
# - Faster failover needed (~9s with tuned timers vs ARP cache timeout)
# - Source IP preservation with externalTrafficPolicy: Local
#
# Requirements:
# - UniFi gateway with UniFi OS 4.1.13+ (or UXG-Enterprise 4.1.8+)
# - FRR config uploaded to gateway (generated in unifi/bgp.conf after configure)
#
# REF: https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-v2/
# REF: docs/guides/bgp-unifi-cilium-implementation.md

# -- The IP address of the BGP router (your gateway on the node network)
#    (OPTIONAL) / (e.g. "192.168.1.1" or VLAN gateway like "192.168.23.254")
#    NOTE: Use the gateway IP on the same VLAN as your nodes, not the management IP
# cilium_bgp_router_addr: ""

# -- The BGP ASN for your router (use private range 64512-65534)
#    (OPTIONAL) / (e.g. "64513")
# cilium_bgp_router_asn: ""

# -- The BGP ASN for Kubernetes nodes (must differ from router ASN for eBGP)
#    (OPTIONAL) / (e.g. "64514")
# cilium_bgp_node_asn: ""

# -- Dedicated CIDR for LoadBalancer IPs (separate from node_cidr)
#    (OPTIONAL) / (e.g. "172.20.10.0/24")
#    NOTE: If set, update UniFi prefix-list to match this CIDR
# cilium_lb_pool_cidr: ""

# -- BGP Hold Time in seconds (failure detection = 3x keepalive or hold timeout)
#    (OPTIONAL) / (DEFAULT: 30) / (Minimum: 3)
#    NOTE: Lower values = faster failure detection, but more BGP traffic
# cilium_bgp_hold_time: 30

# -- BGP Keepalive Time in seconds (sent every N seconds to peer)
#    (OPTIONAL) / (DEFAULT: 10) / (Minimum: 1)
# cilium_bgp_keepalive_time: 10

# -- Enable BGP Graceful Restart for smoother failover during Cilium restarts
#    (OPTIONAL) / (DEFAULT: false)
#    NOTE: Requires UniFi FRR config to also enable graceful-restart
# cilium_bgp_graceful_restart: false

# -- Graceful Restart timeout in seconds
#    (OPTIONAL) / (DEFAULT: 120)
# cilium_bgp_graceful_restart_time: 120

# -- Maximum ECMP paths for load balancing across advertising nodes
#    (OPTIONAL) / (DEFAULT: 3)
#    NOTE: When multiple nodes advertise the same LoadBalancer IP, traffic is
#    distributed across up to this many paths for better load distribution
# cilium_bgp_ecmp_max_paths: 3

# -- MD5 password for BGP session authentication (RFC 2385)
#    (OPTIONAL) / Must match password configured in UniFi FRR config
#    NOTE: When set, a Kubernetes Secret will be created and referenced by
#    CiliumBGPPeerConfig for TCP MD5 authentication
# cilium_bgp_password: ""

# =============================================================================
# UNIFI DNS INTEGRATION - Optional for internal DNS via external-dns webhook
# =============================================================================
# When configured, replaces k8s_gateway with native UniFi DNS record management.
# Requires UniFi Network v9.0.0+ for API key authentication (current stable: 9.5.21)

# -- The UniFi controller host URL
#    (OPTIONAL) / (e.g. "https://192.168.1.1")
# unifi_host: ""

# -- The UniFi API key for DNS management
#    (OPTIONAL) / (Created in UniFi Admin → Control Plane → Integrations)
# unifi_api_key: ""

# -- The UniFi site identifier
#    (OPTIONAL) / (DEFAULT: "default")
# unifi_site: ""

# -- Whether using non-UDM hardware (Cloud Key, self-hosted controller)
#    (OPTIONAL) / (DEFAULT: false)
# unifi_external_controller: false

# =============================================================================
# TALOS UPGRADE CONTROLLER (tuppr) - Automated OS/K8s upgrades
# =============================================================================
# tuppr manages Talos OS and Kubernetes upgrades through GitOps-driven CRs.
# Update these versions to trigger automated rolling upgrades.

# -- Talos OS version for automated upgrades
#    (OPTIONAL) / (DEFAULT: "1.12.0")
# talos_version: "1.12.0"

# -- Kubernetes version for automated upgrades
#    (OPTIONAL) / (DEFAULT: "1.35.0")
# kubernetes_version: "1.35.0"

# =============================================================================
# TALOS BACKUP - Automated etcd snapshots with S3 storage
# =============================================================================
# Talos Backup creates periodic etcd snapshots and uploads them to S3-compatible
# storage with Age encryption. Required for disaster recovery.

# -- S3-compatible endpoint for backups (Cloudflare R2 recommended)
#    (OPTIONAL) / (e.g. "https://<account-id>.r2.cloudflarestorage.com")
# backup_s3_endpoint: ""

# -- S3 bucket name for backups
#    (OPTIONAL) / (e.g. "cluster-backups")
# backup_s3_bucket: ""

# -- S3 access key ID
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# backup_s3_access_key: ""

# -- S3 secret access key
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# backup_s3_secret_key: ""

# -- Age public key for backup encryption (use same as cluster Age key)
#    (OPTIONAL) / (e.g. "age1...")
# backup_age_public_key: ""

# =============================================================================
# PROXMOX CSI CONFIGURATION - Optional for persistent storage
# =============================================================================
# Proxmox CSI provisions PersistentVolumes directly on Proxmox storage.
# Requires Proxmox API token with storage permissions.

# -- Enable Proxmox CSI for persistent storage
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_csi_enabled: false

# -- Proxmox API endpoint (shared with other Proxmox integrations)
#    (OPTIONAL) / (e.g. "https://pve.example.com:8006")
# proxmox_endpoint: ""

# -- Proxmox CSI API token ID (format: user@realm!token-name)
#    (OPTIONAL) / (e.g. "kubernetes-csi@pve!csi")
# proxmox_csi_token_id: ""

# -- Proxmox CSI API token secret
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# proxmox_csi_token_secret: ""

# -- Proxmox storage pool for PVs
#    (OPTIONAL) / (e.g. "local-zfs")
# proxmox_csi_storage: ""

# -- Proxmox region identifier (cluster name)
#    (OPTIONAL) / (DEFAULT: "pve")
# proxmox_region: "pve"

# =============================================================================
# PROXMOX CCM CONFIGURATION - Optional for node labeling/lifecycle
# =============================================================================
# Proxmox CCM provides node labeling, lifecycle management, and topology awareness.
# Use Proxmox CCM instead of Talos CCM when running on Proxmox infrastructure.
# NOTE: Talos CCM and Proxmox CCM are mutually exclusive - only one can be enabled.

# -- Enable Proxmox CCM (disables Talos CCM)
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_ccm_enabled: false

# -- Proxmox CCM API token ID (format: user@realm!token-name)
#    (OPTIONAL) / (e.g. "kubernetes-ccm@pve!ccm")
#    NOTE: Use separate token from CSI for least-privilege principle
# proxmox_ccm_token_id: ""

# -- Proxmox CCM API token secret
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# proxmox_ccm_token_secret: ""

# =============================================================================
# INFRASTRUCTURE (OpenTofu/Proxmox) - Optional for VM deployments
# =============================================================================

# -- Proxmox API endpoint
#    (OPTIONAL) / (e.g. "https://pve.example.com:8006/api2/json")
#    Required only for automated VM provisioning via OpenTofu
# proxmox_api_url: ""

# -- Proxmox node name to create VMs on
#    (OPTIONAL) / (e.g. "pve")
# proxmox_node: ""

# -- Proxmox storage for ISO images
#    (OPTIONAL) / (DEFAULT: "local")
# proxmox_iso_storage: ""

# -- Proxmox storage for VM disks
#    (OPTIONAL) / (DEFAULT: "local-lvm")
# proxmox_disk_storage: ""

# -- Global VM resource defaults (fallback for all nodes)
#    Can be overridden by role-specific defaults or per-node in nodes.yaml
#    Fallback chain: per-node -> role-defaults -> global-defaults
# proxmox_vm_defaults:
#   cores: 4           # CPU cores
#   sockets: 1         # CPU sockets
#   memory: 8192       # Memory in MB
#   disk_size: 128     # Disk size in GB
#
# -- Controller node VM defaults (optimized for etcd and control plane)
#    Controllers run etcd, API server, scheduler, and controller-manager
#    When allowSchedulingOnControlPlanes: false (default), no workloads run here
#    Fallback chain: per-node -> controller-defaults -> global-defaults
# proxmox_vm_controller_defaults:
#   cores: 4           # CPU cores (etcd is single-threaded, 4 is plenty)
#   sockets: 1         # CPU sockets
#   memory: 8192       # Memory in MB (8GB sufficient for control plane)
#   disk_size: 64      # Disk size in GB (etcd only, no workloads)
#
# -- Worker node VM defaults (optimized for running workloads)
#    Workers run application pods, require more resources
#    Fallback chain: per-node -> worker-defaults -> global-defaults
# proxmox_vm_worker_defaults:
#   cores: 8           # CPU cores (more for workload scheduling)
#   sockets: 1         # CPU sockets
#   memory: 16384      # Memory in MB (16GB for application pods)
#   disk_size: 256     # Disk size in GB (container images + workloads)
#
# -- Advanced VM settings (Talos-optimized defaults)
# proxmox_vm_advanced:
#   bios: "ovmf"              # UEFI boot (required for Talos)
#   machine: "q35"            # Modern chipset
#   cpu_type: "host"          # CPU type (host = passthrough)
#   scsi_hw: "virtio-scsi-pci"# SCSI controller
#   balloon: 0                # Memory ballooning disabled (K8s)
#   numa: true                # NUMA enabled
#   qemu_agent: true          # QEMU guest agent
#   net_queues: 4             # Multi-queue networking
#   disk_discard: true        # Enable TRIM/discard
#   disk_ssd: true            # SSD emulation
#   tags: ["kubernetes", "linux", "talos"]  # VM tags
#   # Network configuration
#   network_bridge: "vmbr0"   # Proxmox bridge interface for VM networking
#   # Guest OS configuration
#   ostype: "l26"             # Linux 2.6/3.x/4.x/5.x/6.x kernel
#   # Storage flags (Talos-optimized: immutable OS, K8s handles HA)
#   disk_backup: false        # Exclude from Proxmox backup jobs
#   disk_replicate: false     # Disable Proxmox replication

# -- Proxmox API token for OpenTofu VM provisioning
#    Create at: Datacenter → Permissions → API Tokens → Add
#    Format: user@realm!token-name (e.g., root@pam!terraform)
#    NOTE: Separate from CSI/CCM tokens for least-privilege
#    (OPTIONAL) / Required when infrastructure_enabled
# proxmox_api_token_id: ""
# proxmox_api_token_secret: ""

# =============================================================================
# INFRASTRUCTURE CREDENTIALS (OpenTofu R2 State Backend)
# =============================================================================
# Credentials for the tfstate-worker HTTP backend on Cloudflare R2.
# These are used by `task infra:*` commands for state management.

# -- Cloudflare Account ID
#    Dashboard → Overview → Account ID (right sidebar)
#    (OPTIONAL) / Required for R2 state backend
# cf_account_id: ""

# -- tfstate-worker Basic Auth credentials
#    Must match secrets configured in your tfstate-worker deployment
#    (OPTIONAL) / (DEFAULT: "terraform")
# tfstate_username: "terraform"
# tfstate_password: ""

# =============================================================================
# OBSERVABILITY - Monitoring Stack (VictoriaMetrics + Grafana + AlertManager)
# =============================================================================
# Full-stack observability with metrics, logs, and distributed tracing.
# VictoriaMetrics is recommended for homelab (10x less memory than Prometheus).

# -- Enable monitoring stack (VictoriaMetrics/Prometheus + Grafana + AlertManager)
#    (OPTIONAL) / (DEFAULT: false)
# monitoring_enabled: false

# -- Monitoring stack choice: "victoriametrics" or "prometheus"
#    VictoriaMetrics uses ~10x less memory, recommended for homelabs
#    (OPTIONAL) / (DEFAULT: "victoriametrics")
# monitoring_stack: "victoriametrics"

# -- Enable Hubble network observability (requires monitoring_enabled)
#    Provides network flow visibility via Cilium
#    (OPTIONAL) / (DEFAULT: false)
# hubble_enabled: false

# -- Enable Hubble UI web interface
#    (OPTIONAL) / (DEFAULT: false)
# hubble_ui_enabled: false

# -- Grafana subdomain (creates grafana.<cloudflare_domain>)
#    (OPTIONAL) / (DEFAULT: "grafana")
# grafana_subdomain: "grafana"

# -- Metrics retention period
#    (OPTIONAL) / (DEFAULT: "7d")
# metrics_retention: "7d"

# -- Metrics storage size
#    (OPTIONAL) / (DEFAULT: "50Gi")
# metrics_storage_size: "50Gi"

# -- Storage class for monitoring (uses proxmox-zfs if available)
#    (OPTIONAL) / (DEFAULT: "local-path")
# storage_class: "local-path"

# -- Enable infrastructure alerting rules (PrometheusRule)
#    Generates alerts for: Node health, Control Plane, etcd, Cilium, CoreDNS,
#    Envoy Gateway, Certificates, Flux GitOps, Workloads, Storage
#    (OPTIONAL) / (DEFAULT: true)
# monitoring_alerts_enabled: true

# -- Memory utilization % threshold for NodeMemoryHighUtilization alert
#    (OPTIONAL) / (DEFAULT: 90) / (Range: 50-99)
# node_memory_threshold: 90

# -- CPU utilization % threshold for NodeCPUHighUtilization alert
#    (OPTIONAL) / (DEFAULT: 90) / (Range: 50-99)
# node_cpu_threshold: 90

# -- Enable log aggregation with Loki
#    (OPTIONAL) / (DEFAULT: false)
# loki_enabled: false

# -- Log retention period
#    (OPTIONAL) / (DEFAULT: "7d")
# logs_retention: "7d"

# -- Log storage size
#    (OPTIONAL) / (DEFAULT: "50Gi")
# logs_storage_size: "50Gi"

# =============================================================================
# OBSERVABILITY - Distributed Tracing (Optional)
# =============================================================================
# Tempo for distributed tracing with Alloy as the unified collector.

# -- Enable distributed tracing with Tempo
#    Requires monitoring_enabled: true
#    (OPTIONAL) / (DEFAULT: false)
# tracing_enabled: false

# -- Tracing sample rate (percentage, 1-100)
#    100 = trace all requests; 10 = trace 10% of requests
#    (OPTIONAL) / (DEFAULT: 10)
# tracing_sample_rate: 10

# -- Trace retention period
#    (OPTIONAL) / (DEFAULT: "72h")
# trace_retention: "72h"

# -- Trace storage size
#    (OPTIONAL) / (DEFAULT: "10Gi")
# trace_storage_size: "10Gi"

# -- Cluster name for trace metadata
#    (OPTIONAL) / (DEFAULT: "matherlynet")
# cluster_name: "matherlynet"

# -- Observability namespace for Tempo, Alloy, and other monitoring components
#    (OPTIONAL) / (DEFAULT: "monitoring")
# observability_namespace: "monitoring"

# -- Environment tag for traces and logs (production, staging, development)
#    (OPTIONAL) / (DEFAULT: "production")
# environment: "production"

# =============================================================================
# OIDC/JWT CONFIGURATION - Optional for API authentication via SecurityPolicy
# =============================================================================
# JWT-based authentication for API endpoints, validating tokens against JWKS.
# When configured, creates a SecurityPolicy targeting HTTPRoutes with
# label "security: jwt-protected".
# REF: https://gateway.envoyproxy.io/latest/concepts/gateway_api_extensions/security-policy/
# REF: docs/guides/envoy-gateway-observability-security.md

# -- OIDC provider name (used in SecurityPolicy)
#    (OPTIONAL) / (DEFAULT: "keycloak")
# oidc_provider_name: "keycloak"

# -- OIDC issuer URL (JWT token issuer - must match "iss" claim in tokens)
#    (OPTIONAL) / (e.g. "https://auth.example.com/realms/myrealm")
# oidc_issuer_url: ""

# -- OIDC JWKS URI for JWT validation (public keys endpoint)
#    (OPTIONAL) / (e.g. "https://auth.example.com/realms/myrealm/protocol/openid-connect/certs")
# oidc_jwks_uri: ""

# -- Additional claims to extract from JWT and pass as headers
#    (OPTIONAL) / Headers must start with "X-"
#    Example:
#    oidc_additional_claims:
#      - name: "preferred_username"
#        header: "X-Username"
#      - name: "realm_access.roles"
#        header: "X-User-Roles"
# oidc_additional_claims: []

# =============================================================================
# VOLSYNC PVC BACKUP - Automated PVC backups with restic to S3
# =============================================================================
# VolSync provides restic-based PVC backups to S3-compatible storage.
# Enables point-in-time recovery for stateful applications.
# REF: https://volsync.readthedocs.io/en/stable/
# REF: docs/guides/k8s-at-home-remaining-implementation.md

# -- Enable VolSync PVC backup
#    (OPTIONAL) / (DEFAULT: false)
# volsync_enabled: false

# -- S3-compatible endpoint for backups (Cloudflare R2 recommended)
#    (OPTIONAL) / (e.g. "https://<account-id>.r2.cloudflarestorage.com")
# volsync_s3_endpoint: ""

# -- S3 bucket name for VolSync backups
#    (OPTIONAL) / (e.g. "cluster-pvc-backups")
# volsync_s3_bucket: ""

# -- Restic repository password for encryption
#    (OPTIONAL) / (Will be SOPS-encrypted after task configure)
# volsync_restic_password: ""

# -- Backup schedule (cron format)
#    (OPTIONAL) / (DEFAULT: "0 */6 * * *" - every 6 hours)
# volsync_schedule: "0 */6 * * *"

# -- Copy method for creating backups: "Clone" or "Snapshot"
#    Clone: Works with any CSI driver supporting volume cloning (Proxmox CSI)
#    Snapshot: Requires CSI driver with VolumeSnapshot support
#    (OPTIONAL) / (DEFAULT: "Clone")
# volsync_copy_method: "Clone"

# -- Daily backup retention count
#    (OPTIONAL) / (DEFAULT: 7)
# volsync_retain_daily: 7

# -- Weekly backup retention count
#    (OPTIONAL) / (DEFAULT: 4)
# volsync_retain_weekly: 4

# -- Monthly backup retention count
#    (OPTIONAL) / (DEFAULT: 3)
# volsync_retain_monthly: 3

# =============================================================================
# EXTERNAL SECRETS OPERATOR - Sync secrets from external providers
# =============================================================================
# External Secrets Operator syncs secrets from external secret stores.
# Supported providers: 1Password, Bitwarden, HashiCorp Vault
# REF: https://external-secrets.io/
# REF: docs/guides/k8s-at-home-remaining-implementation.md

# -- Enable External Secrets Operator
#    (OPTIONAL) / (DEFAULT: false)
# external_secrets_enabled: false

# -- External secrets provider: "1password", "bitwarden", or "vault"
#    (OPTIONAL) / (DEFAULT: "1password")
# external_secrets_provider: "1password"

# -- 1Password Connect host URL (required when provider is "1password")
#    (OPTIONAL) / (e.g. "http://onepassword-connect:8080")
# onepassword_connect_host: ""

# =============================================================================
# CILIUM NETWORK POLICIES - Zero-Trust Network Security
# =============================================================================
# CiliumNetworkPolicies enforce zero-trust networking with L3-L7 controls.
# Policies are applied per-namespace with explicit ingress/egress allowlists.
# REF: https://docs.cilium.io/en/stable/security/policy/
# REF: docs/research/cilium-network-policies-jan-2026.md

# -- Enable CiliumNetworkPolicies for zero-trust networking
#    Creates namespace-scoped policies with default-deny and explicit allowlists
#    (OPTIONAL) / (DEFAULT: false)
# network_policies_enabled: false

# -- Network policy enforcement mode: "audit" or "enforce"
#    audit: Policies created with enableDefaultDeny: false (observe only via Hubble)
#    enforce: Policies created with enableDefaultDeny: true (active blocking)
#    Start with audit mode to observe traffic patterns before enforcing
#    (OPTIONAL) / (DEFAULT: "audit")
# network_policies_mode: "audit"
