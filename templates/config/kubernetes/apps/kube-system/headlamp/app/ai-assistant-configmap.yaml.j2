#% if headlamp_ai_assistant_enabled | default(false) %#
---
#| ============================================================================= #|
#| Headlamp AI Assistant ConfigMap                                              #|
#| Configures the AI Assistant plugin to use LiteLLM proxy instead of OpenAI   #|
#| REF: https://github.com/headlamp-k8s/plugins/tree/main/ai-assistant          #|
#| REF: https://github.com/kubernetes-sigs/headlamp/issues/3979                 #|
#| ============================================================================= #|
apiVersion: v1
kind: ConfigMap
metadata:
  name: headlamp-ai-assistant-settings
  namespace: kube-system
  labels:
    app.kubernetes.io/name: headlamp
    app.kubernetes.io/component: ai-assistant
  annotations:
    # Headlamp distributed settings annotation for plugin configuration
    # REF: https://github.com/kubernetes-sigs/headlamp/issues/3979
    headlamp.dev/settings-plugin: "headlamp-ai-assistant"
data:
  #| AI Provider Configuration #|
  provider: "#{ headlamp_ai_assistant_provider }#"

  #| LiteLLM Base URL - OpenAI-compatible endpoint #|
  baseURL: "#{ headlamp_ai_assistant_base_url }#"

  #| API Key Secret Reference #|
  # The plugin should read API key from headlamp-secret/ai-assistant-api-key
  apiKeySecretName: "headlamp-secret"
  apiKeySecretKey: "ai-assistant-api-key"
#% endif %#

