---
apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
  namespace: ai-system
data:
  config.yaml: |
    model_list:
      - model_name: gpt-4.1
        litellm_params:
          model: azure/gpt-4.1
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 13107
          rpm: 250
          tpm: 250000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "41"
          access_groups: ["premium-models", "restricted-models", "aangpt-models", "aanai-models"]
          base_model: azure/us/gpt-4.1-2025-04-14

      - model_name: gpt-4.1-nano
        litellm_params:
          model: azure/gpt-4.1-nano
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 13107
          rpm: 450
          tpm: 450000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "42"
          access_groups: ["default-models", "aangpt-models", "aanai-models"]
          base_model: azure/us/gpt-4.1-nano-2025-04-14

      - model_name: gpt-4o-mini
        litellm_params:
          model: azure/gpt-4o-mini
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 4096
          rpm: 5000
          tpm: 500000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "40"
          access_groups: ["default-models", "aangpt-models", "aanai-models"]
          base_model: azure/us/gpt-4o-mini-2024-07-18

      - model_name: o3
        litellm_params:
          model: azure/o3
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 40000
          thinking:
            type: enabled
            budget_tokens: 4096
          merge_reasoning_content_in_choices: true
          rpm: 250
          tpm: 250000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "53"
          access_groups: ["premium-models", "restricted-models", "aangpt-models", "aanai-models"]
          base_model: azure/us/o3-2025-04-16

      - model_name: o4-mini
        litellm_params:
          model: azure/o4-mini
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 40000
          thinking:
            type: enabled
            budget_tokens: 8192
          merge_reasoning_content_in_choices: true
          rpm: 2000
          tpm: 400000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "54"
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/us/o4-mini-2025-04-16

      - model_name: text-embedding-3-small
        litellm_params:
          model: azure/text-embedding-3-small
          litellm_credential_name: azure_credential_us_east
          rpm: 3000
          tpm: 500000
        model_info:
          id: "86"
          mode: embedding
          access_groups: ["default-models", "developer-models"]
          base_model: azure/text-embedding-3-small

      - model_name: text-embedding-ada-002
        litellm_params:
          model: azure/text-embedding-ada-002
          litellm_credential_name: azure_credential_us_east
          rpm: 3000
          tpm: 500000
        model_info:
          id: "88"
          mode: embedding
          access_groups: ["default-models", "developer-models"]
          base_model: azure/text-embedding-ada-002

      - model_name: gpt-5
        litellm_params:
          model: azure/gpt5_series/gpt-5
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 1750
          tpm: 1750000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "10"
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/us/gpt-5-2025-08-07

      - model_name: gpt-5-chat
        litellm_params:
          model: azure/gpt5_series/gpt-5-chat
          litellm_credential_name: azure_credential_us_east2
          thinking: { "type": "enabled", "budget_tokens": 16384 }
          max_completion_tokens: 16384
          merge_reasoning_content_in_choices: true
          rpm: 1750
          tpm: 1750000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "11"
          mode: chat
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/gpt-5-chat-latest

      - model_name: gpt-5-mini
        litellm_params:
          model: azure/gpt5_series/gpt-5-mini
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 2500
          tpm: 2500000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "12"
          access_groups: ["default-models"]
          base_model: azure/us/gpt-5-mini-2025-08-07

      - model_name: gpt-5-nano
        litellm_params:
          model: azure/gpt5_series/gpt-5-nano
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 15000
          tpm: 15000000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "13"
          access_groups: ["default-models"]
          base_model: azure/us/gpt-5-nano-2025-08-07

      - model_name: gpt-5.1
        litellm_params:
          model: azure/gpt5_series/gpt-5.1
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 20000
          tpm: 2000000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "6"
          supports_reasoning: true
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/global/gpt-5.1

      - model_name: gpt-5.2
        litellm_params:
          model: azure/gpt5_series/gpt-5.2
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 22500
          tpm: 2250000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "1"
          mode: chat
          supports_reasoning: true
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/global/gpt-5.2

      - model_name: gpt-audio
        litellm_params:
          model: azure/gpt-audio
          api_base: "os.environ/AZURE_API_BASE_EAST2"
          api_key: "os.environ/AZURE_API_KEY_EAST2"
          api_version: 2025-01-01-preview
          rpm: 250
          tpm: 250000
        model_info:
          id: "96"
          supports_audio_output: true
          supports_audio_input: true
          access_groups: ["premium-models", "restricted-models"]
          disable_background_health_check: true
          base_model: azure/gpt-audio-2025-08-28

      - model_name: gpt-audio-mini
        litellm_params:
          model: azure/gpt-audio-mini
          api_base: "os.environ/AZURE_API_BASE_EAST2"
          api_key: "os.environ/AZURE_API_KEY_EAST2"
          api_version: 2025-01-01-preview
          rpm: 200
          tpm: 100000
        model_info:
          id: "98"
          supports_audio_output: true
          supports_audio_input: true
          access_groups: ["premium-models", "restricted-models"]
          disable_background_health_check: true
          base_model: azure/gpt-audio-mini-2025-10-06

      - model_name: gpt-image-1
        litellm_params:
          model: azure/gpt-image-1
          litellm_credential_name: azure_credential_us_east2
          rpm: 60
        model_info:
          id: "66"
          mode: image_generation
          access_groups: ["premium-models", "restricted-models"]
          base_model: azure/gpt-image-1

      - model_name: gpt-realtime
        litellm_params:
          model: azure/gpt-realtime
          api_base: "os.environ/AZURE_API_BASE_EAST2"
          api_key: "os.environ/AZURE_API_KEY_EAST2"
          api_version: 2024-10-01-preview
          rpm: 200
          tpm: 100000
        model_info:
          id: "92"
          mode: realtime
          access_groups: ["premium-models", "restricted-models"]
          disable_background_health_check: true
          base_model: gpt-realtime-2025-08-28

      - model_name: gpt-realtime-mini
        litellm_params:
          model: azure/gpt-realtime-mini
          api_base: "os.environ/AZURE_API_BASE_EAST2"
          api_key: "os.environ/AZURE_API_KEY_EAST2"
          api_version: 2024-10-01-preview
          rpm: 200
          tpm: 100000
        model_info:
          id: "94"
          mode: realtime
          access_groups: ["premium-models", "restricted-models"]
          disable_background_health_check: true
          base_model: gpt-realtime-mini-2025-10-06

      - model_name: text-embedding-3-large
        litellm_params:
          model: azure/text-embedding-3-large
          litellm_credential_name: azure_credential_us_east2
          rpm: 18000
          tpm: 3000000
        model_info:
          id: "84"
          mode: embedding
          access_groups: ["default-models", "developer-models"]
          base_model: azure/text-embedding-3-large

      - model_name: claude-opus-4-5
        litellm_params:
          model: anthropic/claude-opus-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 1500
          tpm: 1500000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "20"
          supports_reasoning: true
          access_groups: ["premium-models", "restricted-models"]
          base_model: claude-opus-4-5

      - model_name: claude-sonnet-4-5
        litellm_params:
          model: anthropic/claude-sonnet-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 2750
          tpm: 2750000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "21"
          supports_reasoning: true
          access_groups: ["premium-models", "restricted-models"]
          base_model: claude-sonnet-4-5

      - model_name: claude-opus-4-1
        litellm_params:
          model: anthropic/claude-opus-4-1
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 1250
          tpm: 1250000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "22"
          supports_reasoning: true
          access_groups: ["premium-models", "restricted-models"]
          base_model: claude-opus-4-1

      - model_name: claude-haiku-4-5
        litellm_params:
          model: anthropic/claude-haiku-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 2250
          tpm: 2250000
          cache_control_injection_points:
            - location: message
              role: system
        model_info:
          id: "23"
          supports_reasoning: true
          access_groups: ["default-models"]
          base_model: claude-haiku-4-5

      - model_name: cohere-rerank-v3.5
        litellm_params:
          model: cohere/cohere-rerank-v3.5
          api_key: "os.environ/AZURE_COHERE_RERANK_API_KEY"
          api_base: "os.environ/AZURE_COHERE_RERANK_API_BASE"
          max_output_tokens: 4096
        model_info:
          id: "76"
          mode: rerank
          access_groups: ["premium-models", "restricted-models"]
          base_model: cohere-rerank-v3.5

      - model_name: cohere-embed-v-4-0
        litellm_params:
          model: azure_ai/cohere-embed-v-4-0
          api_key: "os.environ/AZURE_COHERE_EMBED_API_KEY"
          api_base: "os.environ/AZURE_COHERE_EMBED_API_BASE"
          input_type: text
        model_info:
          id: "77"
          mode: embedding
          access_groups: ["premium-models", "restricted-models"]
          base_model: cohere-embed-v-4-0
          disable_background_health_check: true

    credential_list:
      - credential_name: azure_credential_us_east
        credential_values:
          api_key: "os.environ/AZURE_API_KEY"
          api_base: "os.environ/AZURE_API_BASE"
          api_version: "os.environ/AZURE_API_VERSION"
        credential_info:
          description: "Azure OpenAI US East credentials"
      - credential_name: azure_credential_us_east2
        credential_values:
          api_key: "os.environ/AZURE_API_KEY_EAST2"
          api_base: "os.environ/AZURE_API_BASE_EAST2"
          api_version: "os.environ/AZURE_API_VERSION_EAST2"
        credential_info:
          description: "Azure OpenAI US East2 credentials"
      - credential_name: azure_credential_anthropic_us_east2
        credential_values:
          api_key: "os.environ/AZURE_ANTHROPIC_API_KEY"
          api_base: "os.environ/AZURE_ANTHROPIC_API_BASE"
        credential_info:
          description: "Azure Anthropic US East2 credentials"

    litellm_settings:
      drop_params: true

      success_callback:
        - "prometheus"
        - "langfuse"
      failure_callback:
        - "prometheus"
        - "langfuse"
      callbacks:
        - "prometheus"
      service_callbacks:
        - "prometheus_system"



      turn_off_message_logging: true
      redact_user_api_key_info: true
      redact_messages_in_exceptions: true
      set_verbose: false
      json_logs: true

      request_timeout: 30

      langfuse_host: "os.environ/LANGFUSE_HOST"
      langfuse_public_key: "os.environ/LANGFUSE_PUBLIC_KEY"
      langfuse_secret: "os.environ/LANGFUSE_SECRET_KEY"
      langfuse_enabled: true
      langfuse_sample_rate: 1.0

      cache: true
      cache_params:
        type: redis
        host: "os.environ/REDIS_HOST"
        port: "os.environ/REDIS_PORT"
        password: "os.environ/REDIS_PASSWORD"
        namespace: "os.environ/REDIS_NAMESPACE"
        max_connections: 100
        supported_call_types: ["acompletion", "atext_completion", "aembedding", "atranscription"]
        mode: default_on
        ttl: 600

      telemetry: false
      tpm_limit: 3500000
      rpm_limit: 35000
      max_file_size_mb: 25
      max_budget: 1000
      budget_duration: 30d

      track_cost_per_model: true
      track_cost_per_team: true
      track_cost_per_user: true

    general_settings:
      master_key: "os.environ/LITELLM_MASTER_KEY"
      database_url: "os.environ/DATABASE_URL"
      database_connection_pool_limit: 20
      database_connection_timeout: 60
      allow_requests_on_db_unavailable: true
      disable_spend_logs: false
      store_model_in_db: "os.environ/STORE_MODEL_IN_DB"
      store_prompts_in_spend_logs: true
      proxy_batch_write_at: 60
      proxy_budget_rescheduler_min_time: 300
      proxy_budget_rescheduler_max_time: 3600
      disable_error_logs: true

      background_health_checks: false
      health_check_interval: 300

    router_settings:
      routing_strategy: simple-shuffle
      enable_pre_call_checks: true
      enable_tag_filtering: true
      timeout: 120
      stream_timeout: 300

      redis_host: "os.environ/REDIS_HOST"
      redis_port: "os.environ/REDIS_PORT"
      redis_password: "os.environ/REDIS_PASSWORD"

      allowed_fails: 3
      cooldown_time: 30
      disable_cooldowns: true
      retry_policy:
        AuthenticationErrorRetries: 1
        TimeoutErrorRetries: 2
        RateLimitErrorRetries: 3
        ContentPolicyViolationErrorRetries: 2
        InternalServerErrorRetries: 3
      allowed_fails_policy:
        BadRequestErrorAllowedFails: 1000
        AuthenticationErrorAllowedFails: 10
        TimeoutErrorAllowedFails: 12
        RateLimitErrorAllowedFails: 10000
        ContentPolicyViolationErrorAllowedFails: 15
        InternalServerErrorAllowedFails: 20

      debug_level: "INFO"
